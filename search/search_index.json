{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"garf - Python library for interacting with reporting APIs","text":""},{"location":"#what-is-garf","title":"What is garf?","text":"<p><code>garf</code> is a Python library for building various connectors to reporting API that provides users with a SQL-like interface to specify what needs to be extracted from the API.</p> <p>Write a query and  <code>garf</code> will do the rest - build the correct request to an API, parse response and write it virtually anywhere.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Rich SQL-like syntax to interact with reporting APIs.</li> <li>Built-in support for writing data into various local / remote storage.</li> <li>Easily extendable to support various APIs.</li> <li>Built-in support for post-processing saved data in BigQuery &amp; SQL databases.</li> <li>Available as library, CLI, FastAPI endpoint.</li> </ul>"},{"location":"#supported-apis","title":"Supported APIs","text":"<ul> <li>YouTube Data API</li> <li>YouTube Analytics API</li> <li>Google Analytics</li> <li>Google Merchant Center</li> <li>Bid Manager</li> <li>Google Ads</li> <li>Search Ads 360</li> <li>REST</li> </ul>"},{"location":"#installation","title":"Installation","text":"pipuv <pre><code>pip install garf-executors\n</code></pre> <pre><code>uv pip install garf-executors\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#cli","title":"CLI","text":"<pre><code>echo 'SELECT id, name AS model, data.color AS color FROM objects' &gt; query.sql\ngarf  query.sql --source rest --source.endpoint=https://api.restful-api.dev\n</code></pre>"},{"location":"#python-library","title":"Python library","text":"<pre><code>from garf.core.fetchers import RestApiReportFetcher\nfrom garf.io import writer\n\nfetcher = RestApiReportFetcher(endpoint='https://api.restful-api.dev')\nquery = 'SELECT id, name AS model, data.color AS color FROM objects'\nreport = fetcher.fetch(query)\n\n# Convert to Pandas\nreport.to_pandas()\n\n# Write to CSV\nwriter.create_writer('csv').write(report, 'api_data')\n</code></pre>"},{"location":"development/create-api-client/","title":"Create API client for garf","text":"<p>ApiClient is responsible for sending request to an API based on the query.</p>"},{"location":"development/create-api-client/#define-apiclient-class","title":"Define ApiClient class","text":"<p>Creating an API client is the easiest way of developing with <code>garf</code>.</p> <p><code>garf-core</code> library has a <code>BaseClient</code> which one mandatory method you need to implement <code>get_response</code>.</p> <p>Your implementation should take an instance of <code>garf.core.query_editor.BaseQueryElements</code> class and return <code>garf.core.api_clients.GarfApiResponse</code>.</p> <ul> <li><code>BaseQueryElements</code> contains various elements parsed from the query such as fields, sorts, filters, and resource to get data from.</li> <li><code>GarfApiReponse</code> contains <code>results</code> property that should be a list of dictionary-like objects.</li> </ul> <p>Let see and example implementation of <code>MyApiClient</code>.</p> <pre><code>from garf.core import api_clients, query_editor\n\nclass MyApiClient(api_clients.BaseClient):\n\n  def get_response(\n    request: query_editor.BaseQueryElements,\n    **kwargs: str\n  ) -&gt; api_clients.GarfApiResponse:\n    results = ... # get results from your API somehow\n    return api_clients.GarfApiResponse(results=results)\n</code></pre>"},{"location":"development/create-api-client/#use-with-apireportfetcher","title":"Use with ApiReportFetcher","text":"<p>Once your ApiClient class is defined, you can use with built-in <code>ApiReportFetcher</code>.</p> <pre><code>from garf.core import ApiReportFetcher\n\napi_client = MyClient()\nreport_fetcher = ApiReportFetcher(api_client=api_client)\n</code></pre> <p>Note</p> <p>Learn more about using <code>ApiReportFetcher</code>.</p>"},{"location":"development/create-api-response-parser/","title":"Create API response parser","text":"<p>If your API client returns lists of structures that are not similar to dictionaries, you might need to implement a custom parser based on <code>garf.core.parsers.BaseParser</code>.</p>"},{"location":"development/create-api-response-parser/#define-parser-class","title":"Define Parser class","text":"<p>The only method you need to implement is <code>parse_row</code>.</p> <pre><code>from garf.core.parsers import BaseParser\n\nclass MyParser(BaseParser):\n\n  def parse_row(row):\n    # Your parsing logic here\n</code></pre>"},{"location":"development/create-api-response-parser/#use-with-apireportfetcher","title":"Use with ApiReportFetcher","text":"<p>Once your Parser class is defined, you can use with built-in <code>ApiReportFetcher</code>.</p> <pre><code>from garf.core import ApiReportFetcher\n\nreport_fetcher = ApiReportFetcher(api_client, parser=MyParser)\n</code></pre> <p>Note</p> <p>Learn more about using <code>ApiReportFetcher</code>.</p>"},{"location":"development/create-garf-library/","title":"How to create your own garf-based library","text":"<p>In order to create your own library follow the steps.</p>"},{"location":"development/create-garf-library/#setup-project","title":"Setup project","text":"<ul> <li> <p>Create a folder <code>&lt;YOUR-LIBRARY&gt;</code> folder with a subfolder <code>garf_&lt;YOUR_LIBRARY&gt;_api</code> name.</p> </li> <li> <p>Create <code>pyproject.toml</code> of the following structure:</p> </li> </ul> <pre><code>[build-system]\nrequires = [\"setuptools &gt;= 61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"garf-&lt;YOUR_API&gt;\"\ndependencies = [\n  \"garf-core\",\n  \"garf-io\",\n]\nversion = \"0.0.1\"\nlicense = {text = \"Apache 2.0\"}\nrequires-python = \"&gt;=3.9\"\ndescription = \"Garf implementation for &lt;YOUR API&gt;\"\nreadme = \"README.md\"\nclassifiers = [\n  \"Development Status :: 4 - Beta\",\n  \"Programming Language :: Python\"\n]\n\n[project.entry-points.garf]\n&lt;YOUR_API&gt; = \"your_library.report_fetcher\"\n</code></pre> <p>Important</p> <p>Ensure that you register your custom report fetcher as an entrypoint for <code>garf</code>:</p> <pre><code>[project.entry-points.garf]\nyour-api = \"your_library.report_fetcher\"\n</code></pre>"},{"location":"development/create-garf-library/#implement-classes","title":"Implement classes","text":"<p>Go to <code>garf_&lt;YOUR_LIBRARY&gt;_api</code> folder and create <code>report_fetcher.py</code> file.</p>"},{"location":"development/create-garf-library/#apiclient","title":"ApiClient","text":"<p>ApiClient is responsible to getting data from an API based on a query.</p> <p>It's up to you how to implement a request to an API given fields, dimensions, resources, filters and sorts you have.</p> <ul> <li>Create <code>&lt;YOUR_LIBRARY&gt;ApiClient</code> class:</li> </ul> <pre><code>from garf.core import api_clients, query_editor\n\n\nclass MyLibraryApiClient(api_clients.BaseClient):\n\n  def get_response(\n    request: query_editor.BaseQueryElements,\n    **kwargs: str\n  ) -&gt; api_clients.GarfApiResponse:\n    results = ... # get results from your API somehow\n    return api_clients.GarfApiResponse(results=results)\n</code></pre>"},{"location":"development/create-garf-library/#reportfetcher","title":"ReportFetcher","text":"<p>ReportFetcher is initialized based on ApiClient and bundles together query and API response parsers as well as built-in queries associated with a concrete API .</p> <ul> <li>Create <code>&lt;YOUR_LIBRARY&gt;ReportFetcher</code> class:</li> </ul> <pre><code>from garf.core import report_fetcher\n\n\nclass MyLibraryApiReportFetcher(report_fetcher.ApiReportFetcher):\n  def __init__(\n    self,\n    api_client: MyLibraryApiClient = MyLibraryApiClient(),\n    **kwargs: str\n    ) -&gt; None:\n    super().__init__(api_client, **kwargs)\n</code></pre>"},{"location":"development/create-garf-library/#install","title":"Install","text":"<p>To test your project install is as an editable package. <pre><code># launch from the &lt;YOUR-LIBRARY&gt; folder\npip install -e .\n</code></pre></p> <p>Note</p> <p>If you thing others will benefit from your package you can now upload your project to pypi.</p>"},{"location":"development/create-garf-library/#run","title":"Run","text":"<p>Once you installed the package you can run it with <code>garf</code> utility:</p> <pre><code>garf query.sql --source YOUR_API\n</code></pre> <p>Note</p> <p>Refer to instructions for fetching data from your API via <code>garf</code> CLI tool.</p>"},{"location":"development/overview/","title":"Build on top of garf","text":"<p>While <code>garf</code> provides you with a lot of built-in functionality it might not be sufficient for an API of your choice.</p> <p>To make <code>garf</code> work with your API explore options below:</p> <ul> <li>Create an API client to be used with <code>ApiReportFetcher</code> class.</li> <li>Create an API response parser to be customize how <code>ApiReportFetcher</code> parses response from API.</li> <li>Create a library and expose it as <code>garf</code> plugin.</li> </ul>"},{"location":"fetchers/bid-manager/","title":"Bid Manager","text":""},{"location":"fetchers/bid-manager/#garf-for-bid-manager-api","title":"garf for Bid Manager API","text":"<p>Interacts with Bid Manager API.</p>"},{"location":"fetchers/bid-manager/#install","title":"Install","text":"<p>Install <code>garf-bid-manager</code> library</p> pipuv <pre><code>pip install garf-executors garf-bid-manager\n</code></pre> <pre><code>uv pip install garf-executors garf-bid-manager\n</code></pre>"},{"location":"fetchers/bid-manager/#usage","title":"Usage","text":""},{"location":"fetchers/bid-manager/#prerequisites","title":"Prerequisites","text":"<ul> <li>Bid Manager API enabled.</li> <li>Credentials configured, can be exposed  as <code>GARF_BID_MANAGER_CREDENTIALS_FILE</code> ENV variable</li> </ul> clipython <pre><code>echo \"\"\"\nSELECT\n  advertiser,\n  metric_clicks AS clicks\nFROM standard\nWHERE advertiser = 1\n  AND dataRange = LAST_7_DAYS\n  \" &gt; query.sql\ngarf query.sql --source bid-manager \\\n  --output csv\n</code></pre> <pre><code>import os\n\nfrom garf.io import writer\nfrom garf.community.google.bid_manager import BidManagerApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  advertiser,\n  metric_clicks AS clicks\nFROM standard\nWHERE advertiser = 1\n  AND dataRange = LAST_7_DAYS\n\"\"\"\n\nfetched_report = (\n  BidManagerApiReportFetcher(\n    credentials_file=os.getenv('GARF_BID_MANAGER_CREDENTIALS_FILE')\n  )\n  .fetch(query)\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'query')\n</code></pre>"},{"location":"fetchers/bid-manager/#available-source-parameters","title":"Available source parameters","text":"name values comments <code>credentials_file</code> File with Oauth or service account credentials You can expose <code>credentials_file</code> as <code>GARF_BID_MANAGER_CREDENTIALS_FILE</code> ENV variable <code>auth_mode</code> Type of authentication: <code>oauth</code> or <code>service_account</code> <code>oauth</code> is the default mode"},{"location":"fetchers/bid-manager/#query-syntax","title":"Query syntax","text":"<p><code>garf-bid-manager</code> uses simplified syntax for writing queries.</p> area Bid Manager garf filters and metrics case upper (FILTER_ADVERTISER) any (filter_advertiser) prefix mandatory (FILTER_ADVERTISER) optional for filters (advertiser) resource case upper (STANDARD) any (standard) <code>IN</code> in filters list each case (i.e. <code>FILTER_ADVERTISER = 1 AND FILTER_ADVERTISER = 2</code>) <code>advertiser IN (1, 2)</code> <code>CUSTOM_DATES</code> in <code>dataRange</code> requires building complex <code>DataRange</code> object <code>dateRange IN (2025-01-01, 2025-12-31)</code>"},{"location":"fetchers/google-ads/","title":"Google Ads","text":""},{"location":"fetchers/google-ads/#garf-for-google-ads-search-ads-360-api","title":"garf for Google Ads &amp; Search Ads 360 API","text":"<p>Interacts with Google Ads API and Search Ads 360 API.</p>"},{"location":"fetchers/google-ads/#install","title":"Install","text":"<p>Install <code>garf-google-ads</code> library</p> pipuv <pre><code>pip install garf-executors garf-google-ads\n</code></pre> <pre><code>uv pip install garf-executors garf-google-ads\n</code></pre>"},{"location":"fetchers/google-ads/#google-ads","title":"Google Ads","text":""},{"location":"fetchers/google-ads/#prerequisites","title":"Prerequisites","text":"<ul> <li>Google Ads API enabled.</li> <li><code>google-ads.yaml</code> file</li> </ul> clipython <pre><code>echo \"\"\"\nSELECT\n  campaign.id,\n  metrics.clicks AS clicks\nFROM campaign\nWHERE segments.date DURING LAST_7_DAYS\n  \" &gt; query.sql\ngarf query.sql --source google-ads \\\n  --output console\n</code></pre> <pre><code>import os\n\nfrom garf.io import writer\nfrom garf.community.google.ads import GoogleAdsApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  campaign.id,\n  metrics.clicks AS clicks\nFROM campaign\nWHERE segments.date DURING LAST_7_DAYS\n\"\"\"\n\nfetched_report = (\n  GoogleAdsApiReportFetcher(\n    path_to_config=os.getenv('GOOGLE_ADS_CONFIGURATION_FILE_PATH')\n  )\n  .fetch(query, account=os.getenv('GOOGLE_ADS_ACCOUNT'))\n)\n\nconsole_writer = writer.create_writer('console')\nconsole_writer.write(fetched_report, 'query')\n</code></pre>"},{"location":"fetchers/google-ads/#available-source-parameters","title":"Available source parameters","text":"name values comments <code>account</code> Account(s) to get data from Can be MCC(s) as well <code>path-to-config</code> Path to <code>google-ads.yaml</code> file <code>~/google-ads.yaml</code> is a default location <code>expand-mcc</code> Whether to force account expansion if MCC is provided <code>False</code> by default <code>customer-ids-query</code> Optional query to find account satisfying specific condition <code>version</code> Version of Google Ads API"},{"location":"fetchers/google-ads/#search-ads-360","title":"Search Ads 360","text":"<p>Note</p> <p>Install extra dependency to work with Search Ads 360 API <pre><code>pip install garf-google-ads[search-ads-360]\n</code></pre></p>"},{"location":"fetchers/google-ads/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Search Ads 360 API enabled.</li> <li><code>search-ads-360.yaml</code> file.</li> </ul> clipython <pre><code>echo \"\"\"\nSELECT\n  campaign.id,\n  metrics.clicks AS clicks\nFROM campaign\nWHERE segments.date DURING LAST_7_DAYS\n  \" &gt; query.sql\ngarf query.sql --source search-ads-360 \\\n  --output console\n</code></pre> <pre><code>import os\n\nfrom garf.io import writer\nfrom garf.community.google.ads import SearchAds360ApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  campaign.id,\n  metrics.clicks AS clicks\nFROM campaign\nWHERE segments.date DURING LAST_7_DAYS\n\"\"\"\n\nfetched_report = (\n  SearchAds360ApiReportFetcher(\n    path_to_config=os.getenv('SEARCH_ADS_360_CONFIGURATION_FILE_PATH')\n  )\n  .fetch(query, account=os.getenv('SEARCH_ADS_360_ACCOUNT'))\n)\n\nconsole_writer = writer.create_writer('console')\nconsole_writer.write(fetched_report, 'query')\n</code></pre>"},{"location":"fetchers/google-ads/#available-source-parameters_1","title":"Available source parameters","text":"name values comments <code>account</code> Account(s) to get data from Can be MCC(s) as well <code>path-to-config</code> Path to <code>search-ads-360.yaml</code> file <code>~/search-ads-360.yaml</code> is a default location <code>expand-mcc</code> Whether to force account expansion if MCC is provided <code>False</code> by default <code>customer-ids-query</code> Optional query to find account satisfying specific condition"},{"location":"fetchers/google-analytics-api/","title":"garf for Google Analytics Data API","text":"<p>Interacts with Google Analytics Data API.</p>"},{"location":"fetchers/google-analytics-api/#install","title":"Install","text":"<p>Install <code>garf-google-analytics</code> library</p> pipuv <pre><code>pip install garf-executors garf-google-analytics\n</code></pre> <pre><code>uv pip install garf-executors garf-google-analytics\n</code></pre>"},{"location":"fetchers/google-analytics-api/#usage","title":"Usage","text":""},{"location":"fetchers/google-analytics-api/#prerequisites","title":"Prerequisites","text":"<ul> <li>Google Analytics API enabled.</li> </ul> clipython <pre><code>echo \"\nSELECT\n  dimension.country AS country,\n  metric.activeUsers AS active_users\nFROM resource\nWHERE\n  start_date &gt;= '2025-09-01'\n  AND end_date &lt;= '2025-09-07'\n\" &gt; query.sql\ngarf query.sql --source google-analytics \\\n  --output csv \\\n  --source.property-id=GA_PROPERTY_ID\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.analytics import GoogleAnalyticsApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  dimension.country AS country,\n  metric.activeUsers AS active_users\nFROM resource\nWHERE\n  start_date &gt;= '2025-09-01'\n  AND end_date &lt;= '2025-09-07'\n\"\"\"\n\nfetched_report = (\n  GoogleAnalyticsApiReportFetcher()\n  .fetch(query, property_id='PROPERTY_ID')\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'query')\n</code></pre>"},{"location":"fetchers/google-analytics-api/#available-source-parameters","title":"Available source parameters","text":"name values comments <code>property_id</code> Google Analytics 4 Property ID"},{"location":"fetchers/merchant-center-api/","title":"garf for Merchant Center API","text":""},{"location":"fetchers/merchant-center-api/#install","title":"Install","text":"<p>Install <code>garf-merchant-api</code> library</p> <pre><code>pip install garf-executors garf-merchant-api\n</code></pre>"},{"location":"fetchers/merchant-center-api/#usage","title":"Usage","text":"<pre><code>garf &lt;PATH_TO_QUERIES&gt; --source merchant-api \\\n  --output &lt;OUTPUT_TYPE&gt; \\\n  --source.&lt;SOURCE_PARAMETER=VALUE&gt;\n</code></pre> <p>where:</p> <ul> <li><code>&lt;PATH_TO_QUERIES&gt;</code> - local or remove files containing queries</li> <li><code>output</code> - output supported by <code>garf-io</code> library.</li> <li><code>&lt;SOURCE_PARAMETER=VALUE</code> - key-value pairs to refine fetching, check available source parameters.</li> </ul>"},{"location":"fetchers/merchant-center-api/#available-source-parameters","title":"Available source parameters","text":"name values comments <code>account</code> Account(s) to get data to Multiple accounts are supported, should be comma-separated"},{"location":"fetchers/overview/","title":"Overview","text":"<p><code>garf-executors</code> and community libraries provide <code>ReportFetcher</code> implementations to fetch data from various APIs.</p> CLI identifier Fetcher Class Library Options <code>bid-manager</code> <code>BidManagerApiReportFetcher</code> <code>garf-bid-manager</code> <code>credentials_file</code>, <code>auth_mode</code> <code>google-ads</code> <code>GoogleAdsApiReportFetcher</code> <code>garf-google-ads</code> <code>account</code>, <code>path-to-config</code>, <code>expand-mcc</code>, <code>customer-ids-query</code>, <code>version</code> <code>google-analytics</code> <code>GoogleAnalyticsApiReportFetcher</code> <code>garf-google-analytics</code> <code>property_id</code> <code>merchant-api</code> <code>MerchantApiReportFetcher</code> <code>garf-merchant-api</code> <code>account</code> <code>rest</code> <code>RestApiReportFetcher</code> <code>garf-core</code> <code>endpoint</code>, <code>apikey</code> <code>search-ads-360</code> <code>SearchAds360ApiReportFetcher</code> <code>garf-google-ads[search-ads-360]</code> <code>account</code>, <code>path-to-config</code>, <code>expand-mcc</code>, <code>customer-ids-query</code> <code>youtube-analytics</code> <code>YouTubeAnalyticsApiReportFetcher</code> <code>garf-youtube</code> <code>youtube-data-api</code> <code>YouTubeDataApiReportFetcher</code> <code>garf-youtube</code> <code>id</code>, <code>forHandle</code>, <code>forUsername</code>, <code>regionCode</code>, <code>chart</code>, <code>videoId</code>"},{"location":"fetchers/rest/","title":"REST","text":"<p><code>garf</code> comes with built-in REST API support.</p> <p>Currently <code>rest</code> fetcher are support working with APIs that have either API key authentication or not authentication at all.</p> <p>Depending on how a particular API provided expects you to provided an API key in request - it can be either included in a query or passed during <code>rest</code> fetcher initialization.</p>"},{"location":"fetchers/rest/#usage","title":"Usage","text":"clipython <pre><code>echo 'SELECT id, name AS model, data.color AS color FROM objects' &gt; query.sql\ngarf query.sql --source rest \\\n  --source.endpoint=https://api.restful-api.dev \\\n  --output csv\n</code></pre> <pre><code>from garf.core.fetchers import RestApiReportFetcher\nfrom garf.io import writer\n\nfetcher = RestApiReportFetcher(endpoint='https://api.restful-api.dev')\nquery = 'SELECT id, name AS model, data.color AS color FROM objects'\nreport = fetcher.fetch(query)\n\nwriter.create_writer('csv').write(report, 'api_data')\n</code></pre>"},{"location":"fetchers/rest/#examples","title":"Examples","text":""},{"location":"fetchers/rest/#openweather-api","title":"OpenWeather API","text":"<p>Important</p> <p>To run the example below use generate OpenWeather Map API key.</p> <p>OpenWeather expects API key to be added as a query parameter, so it should be included as a macro in the query (in <code>WHERE</code> section).</p> clipython <pre><code>echo \"\"\"\nSELECT\n  main.temp AS temperature,\n  weather[0].main AS weather\nFROM weather\nWHERE lat={lat}\n  AND lon={lon}\n  AND appid={api_key}\n\" &gt; weather.sql\n\ngarf weather.sql --source rest \\\n  --source.endpoint=https://api.openweathermap.org/data/2.5 \\\n  --macro.api_key=OPEN_WEATHER_MAP_API_KEY \\\n  --macro.lat=33.44 \\\n  --macro.lon=-94.04 \\\n  --output csv\n</code></pre> <pre><code>from garf.core.fetchers import RestApiReportFetcher\nfrom garf.io import writer\n\nfetcher = RestApiReportFetcher(\n  endpoint='https://api.openweathermap.org/data/2.5'\n)\nquery = \"\"\"\nSELECT\n  main.temp AS temperature,\n  weather[0].main AS weather\nFROM weather\nWHERE lat={lat}\n  AND lon={lon}\n  AND appid={api_key}\n\"\"\"\nreport = fetcher.fetch(\n  query,\n  args={\n    'macro': {\n      'api_key': OPEN_WEATHER_MAP_API_KEY,\n      'lat': 33.44,\n      'lon': -94.04,\n    }\n  }\n)\n\nwriter.create_writer('csv').write(report, 'weather')\n</code></pre>"},{"location":"fetchers/rest/#currency-api","title":"Currency API","text":"<p>Important</p> <p>To run the example below use generate Currency API key.</p> <p>Currency API expects API key to be added as a header, so it should be included as a fetcher specific parameter (<code>--source.apikey</code> in CLI or <code>apikey</code> parameter in <code>RestApiReportFetcher</code> constructor when using Python library).</p> clipython <pre><code>echo \"\"\"\nSELECT\n  data.{currency}.value AS rate\nFROM latest\nWHERE\n  base_currency={base_currency}\n  AND currencies={currency}\n\"\"\" &gt; currency.sql\n\ngarf currency.sql --source rest \\\n  --source.endpoint=https://api.currencyapi.com/v3 \\\n  --source.apikey=CURRENCY_API_KEY \\\n  --macro.base_currency=EUR \\\n  --macro.currency=USD \\\n  --output csv\n</code></pre> <pre><code>from garf.core.fetchers import RestApiReportFetcher\nfrom garf.io import writer\n\nfetcher = RestApiReportFetcher(\n  endpoint='https://api.currencyapi.com/v3',\n  apikey=CURRENCY_API_KEY,\n)\nquery = \"\"\"\nSELECT\n  data.{currency}.value AS rate\nFROM latest\nWHERE\n  base_currency={base_currency}\n  AND currencies={currency}\n\"\"\"\nreport = fetcher.fetch(\n  query,\n  args={\n    'macro': {\n      'base_currency': 'EUR',\n      'currency': 'USD',\n    }\n  }\n)\n\nwriter.create_writer('csv').write(report, 'currency')\n</code></pre>"},{"location":"fetchers/youtube/","title":"YouTube","text":"<p>The <code>garf-youtube</code> library provides a unified way to interact with various YouTube APIs, streamlining data fetching and reporting within the <code>garf</code> framework. It acts as an umbrella library, allowing you to access both the YouTube Data API and the YouTube Analytics API through consistent <code>garf</code> queries.</p>"},{"location":"fetchers/youtube/#overview","title":"Overview","text":"<p><code>garf-youtube</code> simplifies fetching data from YouTube by abstracting away the underlying API complexities. You can write SQL-like queries to specify the data you need, and <code>garf</code> handles the interaction with the appropriate YouTube API endpoint.</p>"},{"location":"fetchers/youtube/#installation","title":"Installation","text":"<p>To use <code>garf-youtube</code>, you typically install it along with <code>garf-executors</code>:</p> pipuv <pre><code>pip install garf-executors garf-youtube\n</code></pre> <pre><code>uv pip install garf-executors garf-youtube\n</code></pre> <p><code>garf-youtube</code> acts as a facade for the YouTube Data API and YouTube Analytics API. Depending on your query, <code>garf</code> will automatically route the request to the correct underlying fetcher.</p>"},{"location":"fetchers/youtube/#youtube-data-api","title":"YouTube Data API","text":""},{"location":"fetchers/youtube/#prerequisites","title":"Prerequisites","text":"<ul> <li>YouTube Data API enabled.</li> <li>API key to access to access YouTube Data API exposed as <code>export GARF_YOUTUBE_DATA_API_KEY=&lt;YOUR_API_KEY&gt;</code></li> </ul> clipython <pre><code>echo \"SELECT id, snippet.title AS channel_name FROM channels\" &gt; query.sql\ngarf query.sql --source youtube-data-api \\\n  --output csv \\\n  --source.id=YOUTUBE_CHANNEL_ID\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeDataApiReportFetcher\n\nquery = 'SELECT id, snippet.title AS channel_name FROM channels'\n\nfetched_report = (\n  YouTubeDataApiReportFetcher()\n  .fetch(query, id=[YOUTUBE_CHANNEL_ID])\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'query')\n</code></pre>"},{"location":"fetchers/youtube/#available-source-parameters","title":"Available source parameters","text":"name values comments <code>id</code> id(s) of YouTube channels or videos Multiple ids are supported, should be comma-separated <code>forHandle</code> YouTube channel handle i.e. @myChannel <code>forUsername</code> YouTube channel name i.e. myChannel <code>regionCode</code> ISO 3166-1 alpha-2 country code i.e. US <code>chart</code> <code>mostPopular</code> Gets most popular in <code>regionCode</code>, can be narrowed down with <code>videoCategoriId</code> <code>videoId</code> id(s) of YouTube Video to get comments from Multiple ids are supported, should be comma-separated"},{"location":"fetchers/youtube/#examples","title":"Examples","text":""},{"location":"fetchers/youtube/#videos","title":"Videos","text":"<p>Gets meta information and statistics for YouTube videos.</p> clipython <pre><code>echo \"\nSELECT\n  id,\n  snippet.publishedAt AS published_at,\n  snippet.title AS title,\n  snippet.description AS description,\n  snippet.channelTitle AS channel,\n  snippet.tags AS tags,\n  snippet.defaultLanguage AS language,\n  snippet.defaultAudioLanguage AS audio_language,\n  status.madeForKids AS made_for_kids,\n  topicDetails.topicCategories AS topics,\n  contentDetails.duration AS duration,\n  contentDetails.caption AS has_caption,\n  statistics.viewCount AS views,\n  statistics.likeCount AS likes,\n  statistics.commentCount AS comments,\n  statistics.favoriteCount AS favourites\nFROM videos\n\" &gt; video_info.sql\n\ngarf video_info.sql --source youtube-data-api \\\n  --output csv \\\n  --source.id=YOUTUBE_VIDEO_ID_1,YOUTUBE_VIDEO_ID_2\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeDataApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  id,\n  snippet.publishedAt AS published_at,\n  snippet.title AS title,\n  snippet.description AS description,\n  snippet.channelTitle AS channel,\n  snippet.tags AS tags,\n  snippet.defaultLanguage AS language,\n  snippet.defaultAudioLanguage AS audio_language,\n  status.madeForKids AS made_for_kids,\n  topicDetails.topicCategories AS topics,\n  contentDetails.duration AS duration,\n  contentDetails.caption AS has_caption,\n  statistics.viewCount AS views,\n  statistics.likeCount AS likes,\n  statistics.commentCount AS comments,\n  statistics.favoriteCount AS favourites\nFROM videos\n\"\"\"\n\nfetched_report = (\n  YouTubeDataApiReportFetcher()\n  .fetch(query, id=[YOUTUBE_VIDEO_ID_1, YOUTUBE_VIDEO_ID_2])\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'video_info')\n</code></pre> <p>Gets YouTube video(s) height and width.</p> clipython <pre><code>echo \"\nSELECT\n  id,\n  player.embedWidth AS width,\n  player.embedHeight AS height\nFROM videos\n\" &gt; video_orientation.sql\n\ngarf video_orientation.sql --source youtube-data-api \\\n  --output csv \\\n  --source.id=YOUTUBE_VIDEO_ID_1,YOUTUBE_VIDEO_ID_2 \\\n  --source.maxWidth=500\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeDataApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  id,\n  player.embedWidth AS width,\n  player.embedHeight AS height\nFROM videos\n\"\"\"\n\nfetched_report = (\n  YouTubeDataApiReportFetcher()\n  .fetch(\n    query,\n    id=[YOUTUBE_VIDEO_ID_1, YOUTUBE_VIDEO_ID_2],\n    maxWidth=500\n  )\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'video_orientation')\n</code></pre>"},{"location":"fetchers/youtube/#channels","title":"Channels","text":"<p>Gets meta information and statistics for YouTube channel(s).</p> clipython <pre><code>echo \"\nSELECT\n  id,\n  snippet.title AS title,\n  snippet.description AS description,\n  snippet.publishedAt AS published_at,\n  snippet.country AS country,\n  snippet.defaultLanguage AS language,\n  status.madeForKids AS made_for_kids,\n  topicDetails.topicCategories AS topics,\n  statistics.videoCount AS videos,\n  statistics.viewCount AS views,\n  statistics.subscriberCount AS subscribers\nFROM channels\n\" &gt; channel_info.sql\n\ngarf channel_info.sql --source youtube-data-api \\\n  --output csv \\\n  --source.id=YOUTUBE_CHANNEL_ID\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeDataApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  id,\n  snippet.title AS title,\n  snippet.description AS description,\n  snippet.publishedAt AS published_at,\n  snippet.country AS country,\n  snippet.defaultLanguage AS language,\n  status.madeForKids AS made_for_kids,\n  topicDetails.topicCategories AS topics,\n  statistics.videoCount AS videos,\n  statistics.viewCount AS views,\n  statistics.subscriberCount AS subscribers\nFROM channels\n\"\"\"\n\nfetched_report = (\n  YouTubeDataApiReportFetcher()\n  .fetch(query, id=[YOUTUBE_CHANNEL_ID])\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'channel_info')\n</code></pre> <p>Gets all public videos from YouTube channel(s)</p> clipython <pre><code>echo \"\nSELECT\n  channel_id,\n  video_id\nFROM builtin.channelVideos\n\" &gt; channel_videos.sql\n\ngarf channel_videos.sql --source youtube-data-api \\\n  --output csv \\\n  --source.id=YOUTUBE_CHANNEL_ID\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeDataApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  channel_id,\n  video_id\nFROM builtin.channelVideos\n\"\"\"\n\nfetched_report = (\n  YouTubeDataApiReportFetcher()\n  .fetch(query, id=[YOUTUBE_CHANNEL_ID])\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'channel_videos')\n</code></pre>"},{"location":"fetchers/youtube/#commentaries","title":"Commentaries","text":"<p>Gets tops level commentaries for YouTube video(s).</p> clipython <pre><code>echo \"\nSELECT\n  id AS commentary_id,\n  snippet.videoId AS video_id,\n  snippet.topLevelComment.snippet.textDisplay AS comment\nFROM commentThreads\n\" &gt; video_commentaries.sql\n\ngarf video_commentaries.sql --source youtube-data-api \\\n  --output csv \\\n  --source.id=YOUTUBE_VIDEO_ID_1,YOUTUBE_VIDEO_ID_2\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeDataApiReportFetcher\n\n\nquery = \"\"\"\nSELECT\n  id AS commentary_id,\n  snippet.videoId AS video_id,\n  snippet.topLevelComment.snippet.textDisplay AS comment\nFROM commentThreads\n\"\"\"\n\nfetched_report = (\n  YouTubeDataApiReportFetcher()\n  .fetch(query, id=[YOUTUBE_VIDEO_ID_1, YOUTUBE_VIDEO_ID_2])\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'video_commentaries')\n</code></pre>"},{"location":"fetchers/youtube/#youtube-analytics-api","title":"YouTube Analytics API","text":""},{"location":"fetchers/youtube/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>YouTube Reporting API enabled.</li> <li>Client ID, client secret and refresh token generated.</li> </ul> <p>Important</p> <p>Please note you'll need to use Web application OAuth2 credentials type and set \"https://developers.google.com/oauthplayground\" as redirect url in it.</p> <ul> <li> <p>Refresh token. You can use OAuth Playground to generate refresh token.</p> <ul> <li>Select <code>https://www.googleapis.com/auth/yt-analytics.readonly</code> scope</li> <li>Enter OAuth Client ID and OAuth Client secret under Use your own OAuth credentials;</li> <li>Click on Authorize APIs</li> </ul> </li> <li> <p>Expose client id,  client secret and refresh token as environmental variables:</p> </li> </ul> cliPython <pre><code>echo \"\"\"\nSELECT\n  dimensions.day AS date,\n  metrics.views AS views\nFROM channel\nWHERE\n  channel==MINE\n  AND startDate = 2025-01-01\n  AND endDate = 2025-12-31\n\" &gt; query.sql\n\ngarf query.sql --source youtube-analytics \\\n  --output csv\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeAnalyticsApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  dimensions.day AS date,\n  metrics.views AS views\nFROM channel\nWHERE\n  channel==MINE\n  AND startDate = 2025-01-01\n  AND endDate = 2025-12-31\n\"\"\"\n\nfetched_report = (\n  YouTubeAnalyticsApiReportFetcher()\n  .fetch(query)\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'report_data')\n</code></pre>"},{"location":"fetchers/youtube/#examples_1","title":"Examples","text":""},{"location":"fetchers/youtube/#channel-views","title":"Channel views","text":"<p>Gets daily number of views for a channel.</p> clipython <pre><code>echo \"\nSELECT\n  dimensions.day AS date,\n  metrics.views AS views\nFROM channel\nWHERE\n  channel==MINE\n  AND startDate = {start_date}\n  AND endDate = {end_date}\n\" &gt; channel_daily_views.sql\n\ngarf channel_daily_views.sql --source youtube-analytics \\\n  --output csv \\\n  --macro.start_date=2025-01-01 \\\n  --macro.end_date=2025-12-31\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeAnalyticsApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  dimensions.day AS date,\n  metrics.views AS views\nFROM channel\nWHERE\n  channel==MINE\n  AND startDate = {start_date}\n  AND endDate = {end_date}\n\"\"\"\n\nfetched_report = (\n  YouTubeAnalyticsApiReportFetcher()\n  .fetch(\n    query,\n    args={\n      'macro': {\n        'start_date': '2025-01-01',\n        'end_date': '2025-12-31',\n      }\n    }\n  )\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'channel_daily_views')\n</code></pre>"},{"location":"fetchers/youtube/#video-retention","title":"Video retention","text":"<p>Gets retention information for a given video.</p> clipython <pre><code>echo \"\nSELECT\n  dimensions.elapsedVideoTimeRatio AS time_ratio,\n  metrics.audienceWatchRatio AS watch_ratio,\n  metrics.relativeRetentionPerformance AS retention\nFROM channel\nWHERE\n  channel==MINE\n  AND audienceType==ORGANIC\n  AND video=={video_id}\n  AND startDate = {start_date}\n  AND endDate = {end_date}\n\" &gt; video_retention.sql\n\ngarf video_retention.sql --source youtube-analytics \\\n  --output csv \\\n  --macro.video_id=YOUTUBE_VIDEO_ID \\\n  --macro.start_date=2025-01-01 \\\n  --macro.end_date=2025-12-31\n</code></pre> <pre><code>from garf.io import writer\nfrom garf.community.google.youtube import YouTubeAnalyticsApiReportFetcher\n\nquery = \"\"\"\nSELECT\n  dimensions.elapsedVideoTimeRatio AS time_ratio,\n  metrics.audienceWatchRatio AS watch_ratio,\n  metrics.relativeRetentionPerformance AS retention\nFROM channel\nWHERE\n  channel==MINE\n  AND audienceType==ORGANIC\n  AND video=={video_id}\n  AND startDate = {start_date}\n  AND endDate = {end_date}\n\"\"\"\n\nfetched_report = (\n  YouTubeAnalyticsApiReportFetcher()\n  .fetch(\n    query,\n    args={\n      'macro': {\n        'video_id': YOUTUBE_VIDEO_ID,\n        'start_date': '2025-01-01',\n        'end_date': '2025-12-31',\n      }\n    }\n  )\n)\n\ncsv_writer = writer.create_writer('csv')\ncsv_writer.write(fetched_report, 'video_retention')\n</code></pre>"},{"location":"get-started/","title":"Overview","text":"<p>Let's use <code>garf</code> to query https://restful-api.dev (publicly available API) and save results to BigQuery.</p>"},{"location":"get-started/#installation","title":"Installation","text":"pipuv <pre><code>pip install garf-executors\n</code></pre> <pre><code>uv pip install garf-executors\n</code></pre>"},{"location":"get-started/#create-query","title":"Create query","text":"<p>https://restful-api.dev has <code>https://api.restful-api.dev/objects</code> endpoint to get list of objects in the following format:</p> <pre><code>[\n   {\n      \"id\": \"1\",\n      \"name\": \"Google Pixel 6 Pro\",\n      \"data\": {\n         \"color\": \"Cloudy White\",\n         \"capacity\": \"128 GB\"\n      }\n   },\n   {\n      \"id\": \"2\",\n      \"name\": \"Apple iPhone 12 Mini, 256GB, Blue\",\n      \"data\": null\n   },\n   {\n      \"id\": \"3\",\n      \"name\": \"Apple iPhone 12 Pro Max\",\n      \"data\": {\n         \"color\": \"Cloudy White\",\n         \"capacity GB\": 512\n      }\n   }\n]\n</code></pre> <p>Support we want to get <code>id</code>, <code>name</code> and <code>color</code> of each device.</p> <p>Let's create a query to get this information.</p> <pre><code>SELECT\n  id AS device_id,\n  name AS device_name,\n  data.color AS device_color\nFROM objects\n</code></pre> <p>We can save this query to a local file called <code>devices.sql</code>.</p> <pre><code>echo \"\nSELECT\n  id AS device_id,\n  name AS device_name,\n  data.color AS device_color\nFROM objects\" &gt; devices.sql\n</code></pre>"},{"location":"get-started/#execute-query","title":"Execute query","text":"<p>Since the API we're working with is of REST type we can use <code>garf</code>'s built-in <code>rest</code> source and provide API address to get data from.</p> <p>We'll use <code>garf</code> CLI tool get the data. The only thing we need to specify is root endpoint where API is located (<code>https://api.restful-api.dev</code> in our case).</p> <pre><code>garf devices.sql --source rest \\\n  --source.endpoint=https://api.restful-api.dev \\\n  --output bq\n</code></pre> <p>Note</p> <p>Since we want to write data to BigQuery we specified <code>bq</code> output type. By default results will be stored in default project (<code>GOOGLE_CLOUD_PROJECT</code>) in <code>garf</code> dataset under name <code>devices</code>.</p>"},{"location":"get-started/#next-steps","title":"Next steps","text":"<p>Congratulations, you executed your first query with <code>garf</code>!</p> <p>Now you can explore various options <code>garf</code> provides:</p> <ul> <li>How to write queries: Learn an extensive SQL syntax capabilities <code>garf</code> supports.</li> <li>How to use garf in your Python projects: <code>garf</code> makes it easy to fetch data and works with fetched reports.</li> <li>Supported writers: Learn where you can write data fetched from your APIs.</li> <li>Executors: Learn how to process multiple queries with executors.</li> </ul>"},{"location":"usage/api-client/","title":"API clients","text":"<p>ApiClient is responsible for sending request to an API based on the query.</p>"},{"location":"usage/api-client/#built-in-api-clients","title":"Built-in API clients","text":""},{"location":"usage/api-client/#fake","title":"Fake","text":"<p><code>FakeApiClient</code> is ideal for prototyping and test.</p> <p>It allows you to specify sample response from an API as JSON or a dictionary.</p> <pre><code>from garf.core.api_clients import FakeApiClient\n\nfake_data = [\n  {'field1': {'subfield': 1}, 'field2': 2},\n  {'field1': {'subfield': 10}, 'field2': 2},\n]\napi_client = FakeApiClient(results=fake_data)\n</code></pre> <p>Instead of providing data as a variable you can read them from JSON or CSV.</p> <pre><code>from garf.core.api_clients import FakeApiClient\n\napi_client = FakeApiClient.from_json('path/to/json')\napi_client = FakeApiClient.from_csv('path/to/csv')\n</code></pre> <p>Note</p> <p>You can simplify fetching fake data with <code>FakeApiReportFetcher</code>.</p>"},{"location":"usage/api-client/#rest","title":"REST","text":"<p>REST API client is useful when you have a REST API available. Provide endpoint to get data from.</p> <pre><code>from garf.core.api_clients import RestApiClient\n\nendpoint= 'https://api.restful-api.dev'\napi_client = RestApiClient(endpoint=endpoint)\n</code></pre> <p>Note</p> <p>You can simplify fetching from REST API with <code>RestApiReportFetcher</code>.</p>"},{"location":"usage/api-client/#create-api-client","title":"Create API client","text":"<p>If you want to get reports from different APIs you need to implement new API Client.</p> <p>Please refer to development docs to learn more.</p>"},{"location":"usage/core/","title":"Overview","text":"<p><code>garf-core</code> contains the base abstractions are used by an implementation for a concrete reporting API.</p> <p>These abstractions are designed to be as modular and simple as possible:</p> <ul> <li><code>BaseApiClient</code> - an interface for connecting to APIs.</li> <li><code>BaseParser</code> - an interface to parse results from the API.</li> <li><code>ApiReportFetcher</code> - responsible for fetching and parsing data from reporting API.</li> <li><code>GarfReport</code> - contains data from API in a format that is easy to write and interact with.</li> <li><code>QuerySpecification</code> - parsed SQL-query into various elements.</li> <li><code>BaseQuery</code> - protocol for all class based queries.</li> </ul>"},{"location":"usage/core/#installation","title":"Installation","text":"pipuv <pre><code>pip install garf-core\n</code></pre> <pre><code>uv pip install garf-core\n</code></pre>"},{"location":"usage/executors/","title":"Overview","text":"<p><code>garf-executors</code> is responsible for orchestrating process of fetching from API and storing data in a storage.</p> <p>Currently the following executors are supported:</p> <ul> <li><code>ApiExecutor</code> - fetching data from reporting API and saves it to a requested destination.</li> <li><code>BigQueryExecutor</code> - executes SQL code in BigQuery.</li> <li><code>SqlExecutor</code> - executes SQL code in a SqlAlchemy supported DB.</li> </ul>"},{"location":"usage/executors/#installation","title":"Installation","text":"apibigquerysqlalchemyserver <pre><code>pip install garf-executors\n</code></pre> <pre><code>pip install garf-executors[bq]\n</code></pre> <pre><code>pip install garf-executors[sql]\n</code></pre> <pre><code>pip install garf-executors[server]\n</code></pre>"},{"location":"usage/executors/#usage","title":"Usage","text":"<p>After <code>garf-executors</code> is installed you can use <code>garf</code> utility to perform fetching.</p> cliPythonserver <pre><code>garf &lt;QUERIES&gt; --source &lt;API_SOURCE&gt; \\\n  --output &lt;OUTPUT_TYPE&gt;\n</code></pre> <p>where</p> <ul> <li><code>query</code> - local or remote path(s) to files with queries.</li> <li><code>source</code>- type of API to use. Based on that the appropriate report fetcher will be initialized.</li> <li><code>output</code> - output supported by <code>garf-io</code> library.</li> </ul> <pre><code>from garf.executors import api_executor\n\n\nquery_executor = (\n  api_executor.ApiQueryExecutor.from_fetcher_alias(\n    source='API_SOURCE',\n)\ncontext = api_executor.ApiExecutionContext(writer='OUTPUT_TYPE')\n\nquery_text = 'YOUR_QUERY_HERE'\n\nquery_executor.execute(\n  query=query_text,\n  title=\"query\",\n  context=context\n)\n</code></pre> <p>Note</p> <p>You can use <code>aexecute</code> method to run execute the query asynchronously <pre><code>await query_executor.aexecute(\n  query=query_text,\n  title=\"query\",\n  context=context\n)\n</code></pre></p> <p>Note</p> <p>Ensure that API endpoint for <code>garf</code> is running. <pre><code>python -m garf.executors.entrypoints.server\n</code></pre></p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"API_SOURCE\",\n  \"title\": \"query\",\n  \"query\": \"YOUR_QUERY_HERE\",\n  \"context\": {\n    \"writer\": \"OUTPUT_TYPE\"\n  }\n}'\n</code></pre>"},{"location":"usage/executors/#customization","title":"Customization","text":""},{"location":"usage/executors/#source","title":"Source","text":"<p>If your report fetcher requires additional parameters (accounts, ids, regions, categories, etc.) you can easily provide them.</p> <p>Note</p> <p>Concrete <code>--source</code> parameters are dependent on a particular report fetcher and should be looked up in a documentation for this fetcher.</p> cliPythonserver <pre><code>garf &lt;QUERIES&gt; --source &lt;API_SOURCE&gt; \\\n  --output &lt;OUTPUT_TYPE&gt; \\\n  --source.params1=&lt;VALUE&gt;\n</code></pre> <p>where</p> <ul> <li><code>query</code> - local or remote path(s) to files with queries.</li> <li><code>source</code>- type of API to use. Based on that the appropriate report fetcher will be initialized.</li> <li><code>output</code> - output supported by <code>garf-io</code> library.</li> </ul> <pre><code>from garf.executors import api_executor\n\n\nquery_executor = (\n  api_executor.ApiQueryExecutor.from_fetcher_alias(\n    source='API_SOURCE',\n)\ncontext = api_executor.ApiExecutionContext(\n  writer='OUTPUT_TYPE',\n  fetcher_parameters={\n    'param1': 'VALUE',\n  }\n)\n\nquery_text = 'YOUR_QUERY_HERE'\n\nquery_executor.execute(\n  query=query_text,\n  title=\"query\",\n  context=context\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"API_SOURCE\",\n  \"title\": \"query\",\n  \"query\": \"YOUR_QUERY_HERE\",\n  \"context\": {\n    \"writer\": \"OUTPUT_TYPE\",\n    \"fetcher_parameters\": {\n      \"param1\": \"VALUE\"\n    }\n  }\n}'\n</code></pre>"},{"location":"usage/executors/#macro","title":"Macro","text":"<p>If your query contains macros you can provide values for them. Macros will be substituted by any value provided.</p> cliPythonserver <pre><code>echo 'SELECT {key} AS value FROM resource' &gt; query.sql\n\ngarf query.sql --source &lt;API_SOURCE&gt; \\\n  --output &lt;OUTPUT_TYPE&gt; \\\n  --macro.key=VALUE\n</code></pre> <pre><code>from garf.executors import api_executor\n\n\nquery_executor = (\n  api_executor.ApiQueryExecutor.from_fetcher_alias(\n    source='API_SOURCE',\n)\ncontext = api_executor.ApiExecutionContext(\n  writer='OUTPUT_TYPE',\n  query_parameters={\n    'query_parameters': {\n      'macro': {\n        'key': 'VALUE',\n      }\n    }\n  }\n)\n\nquery_text = 'SELECT {key} AS value FROM resource'\n\nquery_executor.execute(\n  query=query_text,\n  title=\"query\",\n  context=context\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"API_SOURCE\",\n  \"title\": \"query\",\n  \"query\": \"YOUR_QUERY_HERE\",\n  \"context\": {\n    \"writer\": \"OUTPUT_TYPE\",\n    \"query_parameters\": {\n      \"macro\":  {\n        \"key\": \"VALUE\"\n      }\n    }\n  }\n}'\n</code></pre>"},{"location":"usage/executors/#template","title":"Template","text":"<p>If your query contains templates you can provide values for them. Template will be dynamically change the query based on provided inputs.</p> cliPythonserver <pre><code>echo \"\"\"\nSELECT\n  {% if key == '0' %}\n  column_1\n  {% else %}\n  column_2\n  {% endif %}\nFROM resource\n\"\"\" &gt; query.sql\n\ngarf query.sql --source &lt;API_SOURCE&gt; \\\n  --output &lt;OUTPUT_TYPE&gt; \\\n  --template.key=VALUE\n</code></pre> <pre><code>from garf.executors import api_executor\n\n\nquery_executor = (\n  api_executor.ApiQueryExecutor.from_fetcher_alias(\n    source='API_SOURCE',\n)\ncontext = api_executor.ApiExecutionContext(\n  writer='OUTPUT_TYPE',\n  query_parameters={\n    'query_parameters': {\n      'template': {\n        'key': 'VALUE',\n      }\n    }\n  }\n)\n\nquery_text = \"\"\"\nSELECT\n  {% if key == '0' %}\n  column_1\n  {% else %}\n  column_2\n  {% endif %}\nFROM resource\n\"\"\"\n\nquery_executor.execute(\n  query=query_text,\n  title=\"query\",\n  context=context\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"API_SOURCE\",\n  \"title\": \"query\",\n  \"query\": \"SELECT {% if key == '0' %} column_1 {% else %} column_2 {% endif %} FROM resource\",\n  \"context\": {\n    \"writer\": \"OUTPUT_TYPE\",\n    \"query_parameters\": {\n      \"template\":  {\n        \"key\": \"VALUE\"\n      }\n    }\n  }\n}'\n</code></pre>"},{"location":"usage/executors/#batch-execution","title":"Batch execution","text":"<p>You can to execute multiple queries in parallel.</p> cliPythonserver <pre><code>garf *.sql --source &lt;API_SOURCE&gt; \\\n  --output &lt;OUTPUT_TYPE&gt; \\\n  --parallel-threshold 10\n</code></pre> <pre><code>from garf.executors import api_executor\n\n\nquery_executor = (\n  api_executor.ApiQueryExecutor.from_fetcher_alias(\n    source='API_SOURCE',\n)\ncontext = api_executor.ApiExecutionContext(\n  writer='OUTPUT_TYPE',\n)\n\nquery_text_1 = \"SELECT column FROM resource1\"\nquery_text_2 = \"SELECT column FROM resource2\"\nbatch = {\n  'query_1': query_text_1,\n  'query_2': query_text_2,\n}\n\nquery_executor.execute_batch(\n  batch=batch,\n  context=context,\n  parallel_threshold=10,\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute:batch' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"API_SOURCE\",\n  \"query_path\": [\n    \"path/to/query1.sql\",\n    \"path/to/query2.sql\"\n  ],\n  \"context\": {\n    \"writer\": \"OUTPUT_TYPE\"\n  }\n}'\n</code></pre>"},{"location":"usage/exporters/","title":"garf exporter - Prometheus exporter for garf.","text":"<p><code>garf-exporter</code> is responsible exposing garf-extracted data to Prometheus.</p>"},{"location":"usage/exporters/#installation","title":"Installation","text":"pipuv <pre><code>pip install garf-exporter\n</code></pre> <pre><code>uv pip install garf-exporter\n</code></pre>"},{"location":"usage/exporters/#usage","title":"Usage","text":"<p><code>garf-exporter</code> expects a configuration file that contains garf-queries mapped to collector names.</p> <p>Config file may contains one or several queries.</p> <pre><code>- title: test\n  query: |\n    SELECT\n      dimension,\n      metric,\n      metric_clicks,\n      campaign\n    FROM resource\n</code></pre> <p>Important</p> <p>To treat any field in SELECT statement as metric prefix with with <code>metric_</code>.</p> <p>You need to explicitly specify source of API and path to config file to start exporting data.</p> <pre><code>garf-exporter --source API_SOURCE -c config.yaml\n</code></pre> <p>Once <code>garf-exporter</code> is running you can see exposed metrics at <code>localhost:8000/metrics</code>.</p>"},{"location":"usage/exporters/#customization","title":"Customization","text":""},{"location":"usage/exporters/#exporter","title":"Exporter","text":"<ul> <li><code>--config</code> - path to <code>garf_exporter.yaml</code>, can be taken from local or remote file.</li> <li><code>--expose-type</code> - type of exposition (<code>http</code> or <code>pushgateway</code>, <code>http</code> is used by default)</li> <li><code>--host</code> - address of your http server (<code>localhost</code> by default)</li> <li><code>--port</code> - port of your http server (<code>8000</code> by default)</li> <li><code>--delay-minutes</code> - delay in minutes between scrapings (<code>15</code> by default)</li> </ul>"},{"location":"usage/exporters/#source","title":"Source","text":"<p>Depending on a source selected you may need to provide source-specific parameters in <code>--source.key=value</code> format (i.e. <code>--source.credentials_file=/app/credentials.json</code>).</p>"},{"location":"usage/exporters/#macro","title":"Macro","text":"<p>If queries contain macros you need provide them in <code>--macros.key=value</code> format (i.e. <code>--macro.start-date=20250101</code>).</p>"},{"location":"usage/exporters/#examples","title":"Examples","text":""},{"location":"usage/exporters/#bid-manager-api","title":"Bid Manager API","text":"<ol> <li> <p>Ensure that Bid Manager access is configured.</p> </li> <li> <p>Specify config</p> </li> </ol> <pre><code>- title: performance\n  query: |\n    SELECT\n      advertiser,\n      metric_clicks\n    FROM standard\n    WHERE advertiser = {advertiser}\n      AND dataRange = CURRENT_DAY\n  suffix: \"Remove\"\n</code></pre> <ol> <li>Start exporting</li> </ol> <pre><code>garf-exporter \\\n  --source bid-manager \\\n  -c config.yaml \\\n  --macro.advertiser=ADVERTISER_ID\n</code></pre>"},{"location":"usage/fetcher/","title":"ApiReportFetcher","text":"<p>ApiReportFetcher is reponsible for getting report from an API based on provided query.</p>"},{"location":"usage/fetcher/#initialization","title":"Initialization","text":""},{"location":"usage/fetcher/#api-client","title":"Api Client","text":"<p>To initialize <code>ApiReportFetcher</code> you need an instance of an API client to interact with an API. You can choose from built-in API clients or create your own. <pre><code>from garf.core import ApiReportFetcher\n\nreport_fetcher = ApiReportFetcher(api_client)\n</code></pre></p>"},{"location":"usage/fetcher/#parser","title":"Parser","text":"<p>Under the hood <code>ApiReportFetcher</code> fetches data from an API as list of dictionaries and tries to access elements in each dictionary via <code>DictParser</code>.</p> <p>You can overwrite this behaviour by using one of built-in parsers or implementing your own.</p> <p>Suppose you want to use <code>NumericConverterDictParser</code> to automatically convert strings to int/float whenever possible.</p> <pre><code>from garf.core import ApiReportFetcher\nfrom garf.core.parsers import NumericConverterDictParser\n\nreport_fetcher = ApiReportFetcher(\n  api_client=api_client,\n  parser=NumericConverterDictParser\n)\n</code></pre>"},{"location":"usage/fetcher/#built-in-queries","title":"Built-in queries","text":"<p>Some queries for a particular API can be quite common so you want to create one or several built-in queries.</p> <p>You can specified them in <code>builtin_queries</code> parameters during <code>ApiReportFetcher</code> initialization.</p> <pre><code>from garf.core import ApiReportFetcher\nfrom garf.core.report import GarfReport\nfrom garf.core.parsers import NumericConverterDictParser\n\ndef builtin_query(fetcher: ApiReportFetcher) -&gt; GarfReport:\n  return fetcher.fetch('SELECT field FROM resource')\n\n\nbuiltin_queries = {'my_query': builtin_query}\n\nreport_fetcher = ApiReportFetcher(\n  api_client=api_client,\n  builtin_queries=builtin_queries\n)\n</code></pre>"},{"location":"usage/fetcher/#fetching","title":"Fetching","text":"<p>To fetch data from an API use <code>fetch</code> method.</p> <pre><code>from garf.core import ApiReportFetcher\n\nreport_fetcher = ApiReportFetcher(api_client)\nquery = 'SELECT metric FROM resource'\nreport = report_fetcher.fetch(query)\n</code></pre> <p>Note</p> <p>You can use <code>afetch</code> method to run execute the query asynchronously <pre><code>report = await report_fetcher.afetch(query)\n</code></pre></p> <p><code>fetch</code> method returns <code>GarfReport</code> which can be processed  in Python or written to local / remote storage.</p>"},{"location":"usage/fetcher/#parametrization","title":"Parametrization","text":"<p>If your query contains macros  or templates, you need to pass values for them via <code>args</code> parameters.</p> <pre><code>from garf.core import ApiReportFetcher\nfrom garf.core.query_editor import GarfQueryParameters\n\nreport_fetcher = ApiReportFetcher(api_client)\n\nquery = 'SELECT metric FROM resource WHERE dimension={dimension}'\n\nquery_parameters = GarfQueryParameters(\n  macro={'dimension': 'value'},\n  template={'dimension': 'value'},\n)\n\nreport = report_fetcher.fetch(query, args=query_parameters)\n</code></pre> <p>Note</p> <p>You can pass a dictionary instead of <code>GarfQueryParameters</code>.</p> <pre><code>query_parameters = {\n  'macro': {\n    'dimension': 'value',\n  },\n  'template': {\n    'dimension': 'value',\n  }\n}\n\nreport = report_fetcher.fetch(query, args=query_parameters)\n</code></pre>"},{"location":"usage/fetcher/#caching","title":"Caching","text":"<p>You can store and retrieve reports from cache rather that getting them from API.</p> <p>Cache has two default parameters which can be overwritten:</p> <ul> <li><code>cache_path</code> (default is <code>$HOME/.garf/cache</code>)</li> <li><code>cache_ttl_seconds</code> (default is 3600 seconds or 1 hour).</li> </ul> <pre><code>from garf.core import ApiReportFetcher\n\nreport_fetcher = ApiReportFetcher(\n  api_client,\n  enable_cache=True,\n  cache_path='~/.cache',\n  cache_ttl_seconds=4*60*60\n)\n\nquery = 'SELECT metric FROM resource'\n\nreport = report_fetcher.fetch(query)\n</code></pre>"},{"location":"usage/fetcher/#built-in-report-fetchers","title":"Built-in report fetchers","text":"<p>To simplify testing and working with REST APIs <code>garf</code> has two built-in report fetchers:</p> <ul> <li><code>FakeApiReportFetcher</code> - simulates API response based on provided data</li> <li><code>RestApiReportFetcher</code> - interacts with APIs with REST interface.</li> </ul>"},{"location":"usage/fetcher/#fake","title":"Fake","text":"<p><code>FakeApiReportFetcher</code> is based on <code>FakeApiClient</code>.</p> <p>It's ideal for prototyping and testing APIs without interacting with them directly.</p> <pre><code>from garf.core.fetchers import FakeApiReportFetcher\n\nfake_data = [\n  {'field1': {'subfield': 1}, 'field2': 2},\n  {'field1': {'subfield': 10}, 'field2': 2},\n]\nreport_fetcher = FakeApiReportFetcher.from_data(fake_data)\n\nquery = 'SELECT field1.subfield AS column FROM resource'\nreport = report_fetcher.fetch(query)\n</code></pre> <p>Note</p> <p>Instead providing data directly you can use helper methods - <code>from_json</code> and <code>from_csv</code>:</p> <pre><code>report_fetcher = FakeApiReportFetcher.from_json('path/to/json')\nreport_fetcher = FakeApiReportFetcher.from_csv('path/to/csv')\n</code></pre>"},{"location":"usage/fetcher/#rest","title":"Rest","text":"<p><code>RestApiReportFetcher</code> is based on <code>RestApiClient</code>.</p> <p>It's can be used with any API that provides REST interface.</p> <p>You need to provide <code>endpoint</code> parameter which specifies root level address where API exists.</p> <p>When writing queries specify relative address of the resource you want to fetch from (i.e. <code>customers/1/orders</code>).</p> <pre><code>from garf.core.fetchers import RestApiReportFetcher\n\nendpoint= 'https://api.restful-api.dev'\nreport_fetcher = RestApiReportFetcher.from_endpoint(endpoint)\n\nquery = 'SELECT id FROM objects'\nreport = report_fetcher.fetch(query)\n</code></pre>"},{"location":"usage/parsers/","title":"API Response parsers","text":"<p>Once ApiClient returns response from an API it's Parser's job to convert it to the format consumable by <code>GarfReport</code>.</p>"},{"location":"usage/parsers/#built-in-parsers","title":"Built-in parsers","text":"<ul> <li><code>DictParser</code> - return an element from API following the attribute path.</li> <li><code>NumericConverterDictParser</code> - subclass of <code>DictParser</code> but tries to convert strings to int/float if possible.</li> </ul> <p>Important</p> <p>If Parser fails to find an element if returns <code>None</code>.</p>"},{"location":"usage/parsers/#create-parsers","title":"Create parsers","text":"<p>If response from your API is in the format not supported by built-in parsers you can build you own parser.</p> <p>Please refer to development docs to learn more.</p>"},{"location":"usage/queries/","title":"How to write queries","text":"<p><code>garf</code> uses SQL-like syntax to write queries.</p> <p>There are three ways how you can define a query:</p> <ul> <li>in a variable</li> <li>in a file</li> <li>in a class (useful when you have complex parametrization and validation)</li> </ul> <p>This is how a generic query might look like:</p> <pre><code>SELECT\n  ad_group.id,\n  ad_group.name\nFROM ad_group\n</code></pre> <p>When running this query and saving the results we get pretty long and unreadable column names - <code>ad_group.id</code> and <code>ad_group.name</code>.</p> <p>Things might be more complicated if you want to extract and save such objects as unselectable elements, complex messages and resource names.</p> <p>In order to simplify data extraction and processing when querying data from API we introduce additional syntax (see an example below):</p> <pre><code>SELECT\n    resource.attribute AS column_name_1,\n    resource.attribute:nested.resource AS column_name_3\n    resource.attribute~1 AS column_name_4\nFROM resource\n</code></pre>"},{"location":"usage/queries/#elements","title":"Elements","text":"<ul> <li>Aliases (<code>AS column_name</code>)</li> <li>Nested resources (<code>:nested.resource.name</code>)</li> <li>Resource indices (<code>~position</code>)</li> <li>Virtual columns (<code>metric.name / metric.name_2 AS alias</code>)</li> </ul>"},{"location":"usage/queries/#aliases","title":"Aliases","text":"<p>Alias is used to give a descriptive name to a metric or attribute fetched from API when saving data. So instead of column name <code>campaign.app_campaign_setting.bidding_strategy_goal_type</code> you may use something more user friendly, like <code>bidding_type</code>.</p> <p>Aliases are specified using <code>AS</code> keyword as shown below:</p> <pre><code>SELECT\n    campaign.app_campaign_setting.bidding_strategy_goal_type AS bidding_type\nFROM campaign\n</code></pre> <p>If you don't specify an alias it will be generated as full column name where \".\" replaced with \"_\".</p> <p>Important</p> <p>If you don't want to include a field into a response but a concrete API requires it to be included in request you can ignore it with <code>_</code> for a for a column name.</p> <pre><code>SELECT\n  column_1 AS _,\n  column_2\nFROM resource\n</code></pre>"},{"location":"usage/queries/#nested-resources","title":"Nested Resources","text":"<p>Some fields return structs, and if you want to get a nested attribute scalar value you can use nested resource selectors. One particular example is working with <code>change_event</code> - <code>change_event.new_resource</code> consists of various changes made to an entity and looks something like that:</p> <pre><code>new_resource {\n    campaign {\n        target_cpa {\n            target_cpa_micros: 1000000\n        }\n    }\n}\n</code></pre> <p>In order to extract a particular element (i.e., final value for <code>target_cpa_micros</code>) we use the <code>:</code> syntax - <code>change_event.new_resource:campaign.target_cpa.target_cpas_micros</code>:</p> <pre><code>SELECT\n    change_event.old_resource:campaign.target_cpa.target_cpa_micros AS old_target_cpa,\n    change_event.new_resource:campaign.target_cpa.target_cpa_micros AS new_target_cpa\nFROM change_event\n</code></pre>"},{"location":"usage/queries/#resource-indices","title":"Resource Indices","text":"<p>Resource indices are used to extract a particular element from data type RESOURCE_NAME. I.e., if we want to get resource name for <code>campaign_audience_view.resource_name</code> and save it somewhere, the saved result will contain a string customers/{customer_id}/campaignAudienceViews/{campaign_id}~{criterion_id}. Usually we want to get only the last element from (<code>criterion_id</code>) and it can be extracted with <code>~N</code> syntax  where N is a position of an element you want to extract (indexing is starting from 0).</p> <p>If the resource you're selecting looks like this <code>customers/111/campaignAudienceViews/222~333</code> you can specify <code>campaign_audience_view.resource_name~1</code> to extract the second element (<code>333</code>). If you specify <code>campaign_audience_view.resource_name~0</code> you'll get '222' (the last resource id before ~).</p> <pre><code>SELECT\n    campaign_audience_view.resource_name~1 AS criterion_id\nFROM campaign_audience_view\n</code></pre>"},{"location":"usage/queries/#virtual-columns","title":"Virtual Columns","text":"<p>Virtual columns allow to specify in a query some fields or expressions that are not present in an API.</p> <pre><code>SELECT\n    1 AS counter,\n    metrics.clicks / metrics.impressions AS ctr,\n    metrics.cost_micros * 1e6 AS cost,\n    campaign.app_campaign_setting.bidding_strategy_goal_type AS bidding_type\nFROM campaign\n</code></pre> <p>Virtual columns can contain constants (i.e. <code>1 AS counter</code> will add new column <code>counter</code> filled with <code>1</code>) or expressions.</p> <p>Expressions can contain field selectors, constants and any arithmetics operations with them. For example <code>metrics.clicks / metrics.impressions AS ctr</code> will calculate <code>metrics.clicks / metrics.impressions</code> for each row of API response and store the results in a new column <code>ctr</code>. For this the fields <code>metrics.clicks</code> and <code>metrics.impressions</code> will be fetched implicitly.</p> <p>Or for example <code>campaign.target_cpa.target_cpa_micros / 1000000 AS target_cpa</code> expression will fetch <code>campaign.target_cpa.target_cpa_micros</code> field but return the result of its division by 1000000.</p> <p>The query parser parses a query and remove all columns which are not simple field accessors (i.e. contains anything except field names). For constants columns they will be re-added into result after executing the query. For more complex columns with expressions (i.e. some operations with fields) the result will evaluated using the response from API.</p>"},{"location":"usage/queries/#macros","title":"Macros","text":"<p>You queries can contain macros. Macro is just a substitution in script text, i.e.</p> <pre><code>SELECT\n    campaign.id AS campaign_id,\n    metrics.clicks AS clicks\nFROM campaign\nWHERE\n    segments.date BETWEEN \"{start_date}\" AND \"{end_date}\"\n</code></pre> <p>When this query is executed it's expected that two macros <code>--macro.start_date=...</code> and <code>--macro.end_date=...</code> are supplied to <code>garf</code>.</p>"},{"location":"usage/queries/#macros-in-virtual-columns","title":"Macros in virtual columns","text":"<p>Macros can be used not only in WHERE statements as in the example above but also in the SELECT statement. In that case this macros will be expanded and then treated as a virtual column.</p> <pre><code>SELECT\n    \"{current_date}\" AS date,\n    campaign.id AS campaign_id,\n    campaign_budget.budget_amount_micros AS budget\nFROM campaign\n</code></pre> <p>This will return all campaign budgets and attach current date (i.e. 2023-06-01) as a date column in the output.</p>"},{"location":"usage/queries/#common-macros","title":"Common macros","text":"<p><code>garf</code> by default has several common macros:</p> <ul> <li><code>date_iso</code> - current date in YYYYMMDD format (i.e. 19700101)</li> <li><code>yesterday_iso</code> - previous day date in YYYY-MM-DD format (i.e. 19700101)</li> <li><code>current_date</code> - current_date in YYYY-MM-DD format (i.e. 1970-01-01)</li> <li><code>current_datetime</code> - current datetime in YYYY-MM-DD HH:mm-ss format (i.e. 1970-01-01 00:00:00)</li> </ul>"},{"location":"usage/queries/#templates","title":"Templates","text":"<p>Your queries can use templates using Jinja engine.</p> <pre><code>SELECT\n  customer_id AS\n  {% if level == \"0\"  %}\n  root_account_id\n  {% else %}\n  leaf_account_id\n  {% endif %}\nFROM dataset1.table1\n</code></pre> <p>When this query is executed it's expected to have template <code>--template.level=...</code> is supplied to <code>garf</code>.</p> <p>This will create a column named either <code>root_account_id</code> since the specified level is 0.</p> <p>Template are great when you need to create multiple column based on condition:</p> <pre><code>SELECT\n    {% for day in cohort_days %}\n        SUM(GetCohort(lag_data.installs, {{day}})) AS installs_{{day}}_day,\n    {% endfor %}\nFROM asset_performance\n</code></pre> <p>When this query is executed it's expected to have template <code>--template.cohort_days=0,1,3,7</code> is supplied to <code>garf</code>.</p> <p>Please note that all values passed through CLI arguments are strings. But there's a special case - a value containing \",\" - it's converted to an array. It will create 4 columns (named <code>installs_0_day</code>, <code>installs_1_day</code>, etc).</p>"},{"location":"usage/queries/#built-in-queries","title":"Built-in queries","text":"<p><code>garf</code> can also works with built-in queries, which use the following syntax:</p> <pre><code>SELECT * FROM builtin.builtin_query_name\n</code></pre> <p>Built-in query may or may not be provided by a particular fetcher. Please check concrete fetcher documentation.</p>"},{"location":"usage/queries/#queries-as-python-objects","title":"Queries as Python objects","text":"<p>You can define queries in multiple ways.</p>"},{"location":"usage/queries/#as-strings","title":"As strings","text":"<pre><code>query_string = \"SELECT campaign.id FROM campaign\"\n</code></pre>"},{"location":"usage/queries/#as-files","title":"As files","text":""},{"location":"usage/queries/#local","title":"Local","text":"<pre><code>from garf.io import reader\n\nquery_path = \"path/to/query.sql\"\n\n# Instantiate reader\nreader_client = reader.FileReader()\n# And read from the path\nquery = reader_client.read(query_path)\n</code></pre>"},{"location":"usage/queries/#remote","title":"Remote","text":"<pre><code>from garf.io import reader\n\nquery_path = \"gs://PROJECT_ID/path/to/query.sql\"\n\n# Instantiate reader\nreader_client = reader.FileReader()\n# And read from the path\nquery = reader_client.read(query_path)\n</code></pre>"},{"location":"usage/queries/#as-dataclasses","title":"As dataclasses","text":"<pre><code>from dataclasses import dataclass\n\nfrom garf.core.base_query import BaseQuery\n\n@dataclass\nclass Campaigns(BaseQuery):\n  query_text  = \"\"\"\n    SELECT\n      campaign.id\n    FROM campaign\n    WHERE campaign.status = {status}\n    \"\"\"\n  status: str = \"ENABLED\"\n\nquery = Campaigns(status='DISABLED')\n</code></pre>"},{"location":"usage/queries/#as-pydantic-objects","title":"As Pydantic objects","text":"<pre><code>from typing import ClassVar\nfrom pydantic import BaseModel\n\nfrom garf.core.base_query import BaseQuery\n\nclass Campaigns(BaseModel, BaseQuery):\n  query_text: ClassVar[str]  = \"\"\"\n    SELECT\n      campaign.id\n    FROM campaign\n    WHERE campaign.status = {status}\n    \"\"\"\n  status: str = \"ENABLED\"\n\nquery = Campaigns(status='DISABLED')\n</code></pre>"},{"location":"usage/queries/#as-plain-python-classes","title":"As plain python classes","text":"<pre><code>from garf.core.base_query import BaseQuery\n\nclass Campaigns(BaseQuery):\n  query_text  = \"\"\"\n    SELECT\n      campaign.id\n    FROM campaign\n    WHERE campaign.status = {status}\n    \"\"\"\n\n  def __init__(self, status: str = \"ENABLED\") -&gt; None:\n    self.status = status\n\nquery = Campaigns(status='DISABLED')\n</code></pre>"},{"location":"usage/reports/","title":"GarfReport","text":"<p><code>ApiReportFetcher.fetch</code> returns you an instance of <code>GarfReport</code> object.</p> <p>It's a table like structure (resembling pandas DataFrame) which can easily be manipulated.</p>"},{"location":"usage/reports/#iteration","title":"Iteration","text":"<p><code>ApiReportFetcher.fetch</code> method returns an instance of <code>GarfReport</code> object which you can use to perform simple iteration.</p> <pre><code>query_text = \"SELECT campaign.id AS campaign_id, clicks FROM campaign\"\ncampaigns = report_fetcher.fetch(query_text)\n\n# iterate over each row of `campaigns` report\nfor row in campaigns:\n  # Get element as an attribute\n  print(row.campaign_id)\n\n  # Get element as a slice\n  print(row[\"campaign_id\"])\n\n  # Get element as an index\n  print(row[0])\n\n  # Create new column\n  row[\"new_campaign_id\"] = row[\"campaign_id\"] + 1\n</code></pre>"},{"location":"usage/reports/#slicing","title":"Slicing","text":"<p>You can easily slice the report</p> <pre><code># Create new reports by selecting one or more columns\ncampaign_only_report = campaigns[\"campaign_id\"]\ncampaign_name_clicks_report = campaigns[[\"campaign_id\", \"clicks\"]]\n\n# Get subset of the report\n# Get first row only\nfirst_campaign_row = campaigns[0]\n# Get first ten rows from the report\nfirst_10_rows_from_campaigns = campaigns[0:10]\n</code></pre>"},{"location":"usage/reports/#converting","title":"Converting","text":"<p><code>GarfReport</code> can be easily converted to common data structures:</p> <p><pre><code># convert `campaigns` to list of lists\ncampaigns_list = campaigns.to_list()\n\n# convert `campaigns` to flatten list\ncampaigns_list = campaigns.to_list(row_type=\"scalar\")\n\n# convert `campaigns` column campaign_id to list\ncampaigns_list = campaigns[\"campaign_id\"].to_list()\n\n# convert `campaigns` column campaign_id to list with unique values\ncampaigns_list = campaigns[\"campaign_id\"].to_list(distinct=True)\n\n# convert `campaigns` to list of dictionaries\n# each dictionary maps report column to its value, i.e.\n# {\"campaign_name\": \"test_campaign\", \"campaign_id\": 1, \"clicks\": 10}\ncampaigns_list = campaigns.to_list(row_type=\"dict\")\n\n# convert `campaigns` to pandas DataFrame\ncampaigns_df = campaigns.to_pandas()\n\n# convert `campaigns` to polars DataFrame\ncampaigns_df = campaigns.to_polars()\n\n# convert `campaigns` to dictionary\n# map campaign_id to campaign_name one-to-one\ncampaigns_dict = campaigns.to_dict(\n  key_column=\"campaign_id\",\n  value_column=\"clicks\",\n  value_column_output=\"scalar\",\n)\n\n# convert `campaigns` to dictionary\n# map campaign_id to campaign_name one-to-many\ncampaigns_dict = campaigns.to_dict(\n  key_column=\"campaign_id\",\n  value_column_output=\"list\",\n)\n\n# convert `campaigns` to dictionary\n# where values are another dictionary\ncampaigns_dict = campaigns.to_dict(\n  key_column=\"campaign_id\",\n  value_column_output=\"dict\",\n)\n</code></pre> <pre><code>#### Building\n\n`GarfReport` can be easily built from pandas or polars data frame:\n\n```python\nimport pandas as pd\nimport polars as pl\n\n# Pandas\ndf = pd.DataFrame(data=[[1]], columns=[\"one\"])\nreport = GarfReport.from_pandas(df)\n\n# Polars\ndf = pl.DataFrame(data=[[1]], schema=[\"one\"], orient='row')\nreport = GarfReport.from_polars(df)\n</code></pre></p>"},{"location":"usage/reports/#saving","title":"Saving","text":"<p><code>GarfReport</code> can be easily saved to local or remote storage:</p> <pre><code>from garf.io import writer\n\n# initialize CSV writer\ncsv_writer = writer.create_writer('csv', destination_folder=\"/tmp\")\n\n# save report using one of the writers\ncsv_writer.write(campaigns, destination=\"my_file_name\")\n</code></pre>"},{"location":"usage/workflows/","title":"Workflows","text":"<p>Workflows in <code>garf</code> allow you to orchestrate complex data fetching and processing pipelines. Instead of running individual queries, you can define a sequence of steps, where each step interacts with a specific data source (fetcher) and writes to a destination.</p>"},{"location":"usage/workflows/#configuration","title":"Configuration","text":"<p>Workflows are defined in YAML files. The core structure consists of a list of <code>steps</code>, where each step defines what data to fetch and where to save it.</p>"},{"location":"usage/workflows/#workflow-step-structure","title":"Workflow Step Structure","text":"<pre><code>steps:\n  - alias: step_name\n    fetcher: source_name\n    writer: destination\n    writer_parameters:\n      key: value\n    fetcher_parameters:\n      key: value\n    query_parameters:\n      macro:\n        key: value\n      template:\n        key: value\n    queries:\n      - folder: path/to/queries/\n      - path: path/to/query.sql\n      - query:\n          text: \"SELECT 1\"\n          title: \"simple_query\"\n    parallel_threshold: 10\n</code></pre>"},{"location":"usage/workflows/#components","title":"Components","text":"<ul> <li>fetcher: The source of data. Check available fetchers.</li> <li>fetcher_parameters: Key value pairs used to fine-tune fetching process.</li> <li>alias: A unique identifier for the step. Useful for logging and selective execution.</li> <li>writer: Where the data should be saved. Check available writers.</li> <li>writer_parameters: Key value pairs used to fine-tune writing process.</li> <li>query_parameters: (Optional) Parameters for dynamically changing query text.</li> <li>queries: A list of queries to execute in this step. Can be:<ul> <li><code>folder</code>: Recursively finds all <code>.sql</code> files in the directory.</li> <li><code>path</code>: Path to a specific query file.</li> <li><code>query</code>: Inline query definition with <code>text</code> and <code>title</code>.</li> </ul> </li> <li>parallel_threshold: Custom threshold of parallel query execution for a given step.</li> </ul>"},{"location":"usage/workflows/#common-parameters","title":"Common Parameters","text":"<p>You can use YAML anchors and aliases to avoid repetition, which is especially useful for sharing configuration between steps.</p> <pre><code># Define shared configuration\ndefault_bq: &amp;bq_defaults\n  writer: bq\n  writer_parameters:\n    project: my-project\n    dataset: my_dataset\n\nsteps:\n  - alias: step_1\n    fetcher: google-ads\n    &lt;&lt;: *bq_defaults\n    queries: ...\n\n  - alias: step_2\n    fetcher: google-ads\n    &lt;&lt;: *bq_defaults\n    queries: ...\n</code></pre>"},{"location":"usage/workflows/#usage","title":"Usage","text":"cliPythonserver <pre><code>garf -w workflow.yaml\n</code></pre> <pre><code>from garf.executors.workflows import workflow_runner\n\nrunner = workflow_runner.WorkflowRunner.from_file(\"path/to/workflow.yaml\")\nrunner.run()\n</code></pre> <p>Note</p> <p>Ensure that API endpoint for <code>garf</code> is running. <pre><code>python -m garf.executors.entrypoints.server\n</code></pre></p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute:workflow?workflow_file=workflow.yaml' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d ''\n</code></pre>"},{"location":"usage/workflows/#customization","title":"Customization","text":""},{"location":"usage/workflows/#includeexclude-steps","title":"Include/Exclude Steps","text":"<p>Instead of running the whole workflow you can selected or omit certain steps.</p> cliPythonserver <pre><code>garf -w workflow.yaml --workflow-include alias_1 --workflow-exclude alias_3\n</code></pre> <pre><code>from garf.executors.workflows import workflow_runner\n\nrunner = workflow_runner.WorkflowRunner.from_file(\"path/to/workflow.yaml\")\nrunner.run(selected_aliases=['alias_1'], skipped_aliases=['alias_3'])\n</code></pre> <p>Note</p> <p>Ensure that API endpoint for <code>garf</code> is running. <pre><code>python -m garf.executors.entrypoints.server\n</code></pre></p> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute:workflow?workflow_file=workflow.yaml' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"selected_aliases\": [\n    \"alias_1\"\n  ],\n  \"skipped_aliases\": [\n    \"alias_3\"\n  ]\n}'\n</code></pre>"},{"location":"usage/workflows/#example","title":"Example","text":"<p>Here is a comprehensive example showing a multi-step pipeline:</p> <pre><code>bq_project: &amp;bq_project \"my-gcp-project\"\nbq_dataset: &amp;bq_dataset \"marketing_data\"\n\nsteps:\n  # Step 1: Fetch data from Google Ads\n  - alias: ingest_ads\n    fetcher: google-ads\n    fetcher_parameters:\n      account: \"123-456-7890\"\n    writer: bq\n    writer_parameters:\n      project: *bq_project\n      dataset: *bq_dataset\n    queries:\n      - path: queries/ads_reporting/roas.sql\n\n  # Step 2: Filter data in BigQuery and save to CSV\n  - alias: transform_data\n    fetcher: bq\n    fetcher_parameters:\n      project: *bq_project\n    queries:\n      - query:\n          title: \"filtered_roas\"\n          text: \"SELECT roas FROM `{dataset}.roas` WHERE roas &gt; 1\"\n    query_parameters:\n      macro:\n        dataset: *bq_dataset\n    writer: csv\n</code></pre>"},{"location":"usage/writers/","title":"Overview","text":"<p><code>garf-io</code> library is reponsible for writing <code>GarfReport</code> to various local/remote storages.</p> CLI identifier Writer Class Options <code>console</code> ConsoleWriter <code>page-size=10</code>,<code>format=table|json|jsonl</code> <code>csv</code> CsvWriter <code>destination-folder</code> <code>json</code> JsonWriter <code>destination-folder</code>,<code>format=json|jsonl</code> <code>bq</code> BigQueryWriter <code>project</code>, <code>dataset</code>, <code>location</code>, <code>write-disposition</code> <code>sqldb</code> SqlAlchemyWriter <code>connection-string</code>, <code>if-exists=fail|replace|append</code> <code>sheets</code> SheetsWriter <code>share-with</code>, <code>credentials-file</code>, <code>spreadsheet-url</code>, <code>is_append=True|False</code> <code>elasticsearch</code> ElasticsearchWriter <code>hosts</code> <code>excel</code> ExcelWriter <code>destination-folder</code>, <code>file</code> <code>kafka</code> KafkaWriter <code>bootstrap-servers</code> <code>opensearch</code> OpenSearchWriter <code>hosts</code> <code>pubsub</code> PubSubWriter <code>project</code>"},{"location":"usage/writers/#installation","title":"Installation","text":"pipuv <pre><code>pip install garf-io\n</code></pre> <pre><code>uv pip install garf-io\n</code></pre> <p>By default  <code>garf-io</code> has only support for <code>console</code>, <code>csv</code> and <code>json</code> writers.</p> <p>To install all writers use the following command <code>pip install garf-io[all]</code>.</p> <p>To install specific writers use:</p> <ul> <li><code>pip install garf-io[bq]</code> for BigQuery support</li> <li><code>pip install garf-io[sheets]</code> for Google spreadsheets support</li> <li><code>pip install garf-io[sqlalchemy]</code> for SqlAlchemy support</li> <li><code>pip install garf-io[elasticsearch]</code> for Elasticsearch support</li> <li><code>pip install garf-io[excel]</code> for Excel support</li> <li><code>pip install garf-io[kafka]</code> for Kafka support</li> <li><code>pip install garf-io[opensearch]</code> for OpenSearch support</li> <li><code>pip install garf-io[pubsub]</code> for PubSub support</li> </ul>"},{"location":"usage/writers/#usage","title":"Usage","text":"clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output YOUR_WRITER\n</code></pre> <p>Note</p> <p>To use <code>cli</code> example you need to have <code>garf-executors</code> package installed.</p> <pre><code>pip install garf-executors\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io import writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nconcrete_writer = writer.create_writer('YOUR_WRITER')\nconcrete_writer.write(sample_report, 'query')\n</code></pre> <p>Note</p> <p>You can use <code>awrite</code> method to write report asynchronously. <pre><code>await concrete_writer.awrite(sample_report, 'query')\n</code></pre></p>"},{"location":"usage/writers/#configuration","title":"Configuration","text":"<p>Each of writer also support two options for dealing with arrays:</p> <ul> <li><code>WRITER.array-handling</code> - arrays handling method: \"strings\" (default)  - store arrays as strings (items combined via a separator, e.g. \"item1|item2\"), \"arrays\" - store arrays as arrays.</li> <li><code>WRITER.array-separator</code> - a separator symbol for joining arrays as strings, by default '|'.</li> </ul>"},{"location":"usage/executors/api-executor/","title":"ApiExecutor","text":"<p>If your job is to execute query and write it to local/remote storage you can use <code>ApiQueryExecutor</code> to do it easily.</p>"},{"location":"usage/executors/api-executor/#install","title":"Install","text":"<p>Ensure that <code>garf-executors</code> library is installed:</p> <pre><code>pip install garf-executors\n</code></pre>"},{"location":"usage/executors/api-executor/#run","title":"Run","text":"<p>Let's take an example of working with YouTube Data API fetcher to get some stats on YouTube video.</p> <p>Important</p> <p>Make sure that corresponding library for interacting with YouTube Data API is installed</p> <pre><code>pip install garf-youtube\n</code></pre> bashPythonserver <pre><code>echo \"\nSELECT\n  id,\n  snippet.publishedAt AS published_at,\n  snippet.title AS title\nFROM videos\" &gt; query.sql\n\n\ngarf query.sql --source youtube-data-api \\\n  --output csv \\\n  --source.ids=VIDEO_ID\n</code></pre> <p>where</p> <ul> <li><code>query</code> - local or remote path(s) to files with queries.</li> <li><code>source</code>- type of API to use. Based on that the appropriate report fetcher will be initialized.</li> <li><code>output</code> - output supported by <code>garf-io</code> library.</li> </ul> <pre><code>from garf.executors import setup_executor\n\n\nquery_executor = setup_executor(source='youtube-data-api')\ncontext = api_executor.ApiExecutionContext(\n  writer='csv',\n  fetcher_parameters={'id': 'VIDEO_ID'}\n)\n\nquery_text = \"\"\"\nSELECT\n  id,\n  snippet.publishedAt AS published_at,\n  snippet.title AS title\nFROM videos\n\"\"\"\n\nquery_executor.execute(\n  query=query_text,\n  title=\"query\",\n  context=context\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"youtube-data-api\",\n  \"query\": \"SELECT id, snippet.publishedAt AS published_at, snippet.title AS title FROM videos\",\n  \"title\": \"query\",\n  \"context\": {\n    \"writer\": \"csv\",\n    \"fetcher_parameters\": {\n      \"id\": \"VIDEO_ID\"\n    }\n  }\n}'\n</code></pre>"},{"location":"usage/executors/api-executor/#caching","title":"Caching","text":"<p>When running queries you can get data from cache rather that fetching them from API.</p> <p>Cache has <code>cache_ttl_seconds</code> parameter (default is 3600 seconds or 1 hour).</p> bashPythonserver <pre><code>garf query.sql --source youtube-data-api \\\n  --output console \\\n  --source.id=VIDEO_ID \\\n  --enable-cache \\\n  --cache-ttl-seconds 300\n</code></pre> <pre><code>from garf.executors import setup_executor\n\n\nquery_executor = setup_executor(\n  source='youtube-data-api',\n  enable_cache=True,\n  cache_ttl_seconds=300\n)\ncontext = api_executor.ApiExecutionContext(\n  writer='csv',\n  fetcher_parameters={'id': 'VIDEO_ID'}\n)\n\nquery_text = \"\"\"\nSELECT\n  id,\n  snippet.publishedAt AS published_at,\n  snippet.title AS title\nFROM videos\n\"\"\"\n\nquery_executor.execute(\n  query=query_text,\n  title=\"query\",\n  context=context\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"youtube-data-api\",\n  \"query\": \"SELECT id, snippet.publishedAt AS published_at, snippet.title AS title FROM videos\",\n  \"title\": \"query\",\n  \"context\": {\n    \"fetcher_parameters\": {\n      \"id\": \"VIDEO_ID\",\n      \"enable_cache\": True,\n      \"cache_ttl_seconds': 300\n    }\n  }\n}'\n</code></pre>"},{"location":"usage/executors/bq-executor/","title":"BigQuery Executor","text":"<p><code>BigQueryExecutor</code> allows you to execute SQL code in BigQuery.</p>"},{"location":"usage/executors/bq-executor/#install","title":"Install","text":"<p>Ensure that <code>garf-executors</code> library is installed with BigQuery support:</p> <pre><code>pip install garf-executors[bq]\n</code></pre>"},{"location":"usage/executors/bq-executor/#usage","title":"Usage","text":"<p>After <code>garf-executors</code> is installed you can use <code>garf</code> utility to perform fetching.</p> bashPythonserver <p><pre><code>echo \"SELECT campaign_id FROM project.dataset.table\" &gt; query.sql\n\ngarf query.sql --source bq \\\n  --output csv\n</code></pre> where</p> <ul> <li><code>query</code>- local or remote path(s) to files with queries.</li> <li><code>output</code> - output supported by <code>garf-io</code> library.</li> </ul> <pre><code>from garf.executors.bq_executor import BigQueryExecutor\n\n\nquery_executor = BigQueryExecutor()\n\nquery_text = \"SELECT campaign_id FROM project.dataset.table\"\n\n# execute query and get report back\nreport = query_executor.execute(query=query_text, title=\"campaign\")\n\n# execute query and save results to `campaign.csv`\nquery_executor.execute(\n  query=query_text,\n  title=\"campaign\",\n  context={'writer': 'csv'}\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"bq\",\n  \"query\": \"SELECT campaign_id FROM project.dataset.table\",\n  \"title\": \"campaign\",\n  \"context\": {\n    \"writer\": \"csv\"\n  }\n}'\n</code></pre>"},{"location":"usage/executors/bq-executor/#parameters","title":"Parameters","text":""},{"location":"usage/executors/bq-executor/#project","title":"project","text":"<p><code>BigQueryExecutor</code> requires Google Cloud Project ID. It can be passed via <code>project</code> parameter or <code>GOOGLE_CLOUD_PROJECT</code> environment variable.</p> cliPythonserver <pre><code>garf query.sql --source bq \\\n  --output csv \\\n  --bq.project=MY_PROJECT\n</code></pre> <pre><code>from garf.executors.bq_executor import BigQueryExecutor\n\nquery_executor = BigQueryExecutor(project='MY_PROJECT')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"bq\",\n  \"query\": \"SELECT campaign_id FROM project.dataset.table\",\n  \"title\": \"campaign\",\n  \"context\": {\n    \"writer\": \"csv\",\n    \"fetcher_parameters\": {\n      \"project\": \"MY_PROJECT\"\n    }\n  }\n}'\n</code></pre>"},{"location":"usage/executors/bq-executor/#location","title":"location","text":"<p>You can specify BigQuery dataset location via <code>location</code> parameter.</p> cliPythonserver <pre><code>garf query.sql --source bq \\\n  --output csv \\\n  --bq.location=europe-west1\n</code></pre> <pre><code>from garf.executors.bq_executor import BigQueryExecutor\n\nquery_executor = BigQueryExecutor(location='europe-west1')\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"bq\",\n  \"query\": \"SELECT campaign_id FROM project.dataset.table\",\n  \"title\": \"campaign\",\n  \"context\": {\n    \"writer\": \"csv\",\n    \"fetcher_parameters\": {\n      \"location\": \"europe-west1\"\n    }\n  }\n}'\n</code></pre>"},{"location":"usage/executors/duckdb-executor/","title":"DuckDB Executor","text":"<p>DuckDB executor allows you to execute SQL code over various files formats supported by DuckDB.</p>"},{"location":"usage/executors/duckdb-executor/#install","title":"Install","text":"<p>Ensure that <code>garf-executors</code> library is installed with DuckDB support:</p> <pre><code>pip install garf-executors[duckdb]\n</code></pre>"},{"location":"usage/executors/duckdb-executor/#usage","title":"Usage","text":"<p>After <code>garf-executors</code> is installed you can use <code>garf</code> utility to perform fetching.</p> bashPythonserver <p><pre><code>echo \"SELECT campaign_id FROM 'data.csv'\" &gt; query.sql\n\ngarf query.sql --source duckdb --output csv\n</code></pre> where</p> <ul> <li><code>query</code>- local or remote path(s) to files with queries.</li> <li><code>output</code> - output supported by <code>garf-io</code> library.</li> </ul> <pre><code>from garf.executors.duckdb_executor import DuckDBExecutor\n\n\nquery_executor = DuckDBExecutor()\n\nquery_text = \"SELECT campaign_id FROM 'data.csv'\"\n\n# execute query and get report back\nreport = query_executor.execute(query=query_text, title=\"campaign\")\n\n# execute query and save results to `campaign.csv`\nquery_executor.execute(\n  query=query_text,\n  title=\"campaign\",\n  context={'writer': 'csv'}\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"duckdb\",\n  \"query\": \"SELECT campaign_id FROM \\\"data.csv\\\"\",\n  \"title\": \"campaign\",\n  \"context\": {\n    \"writer\": \"csv\"\n  }\n}'\n</code></pre>"},{"location":"usage/executors/opensearch-executor/","title":"OpenSearch Executor","text":"<p>OpenSearch executor allows you to execute SQL code over indexes in OpenSearch.</p>"},{"location":"usage/executors/opensearch-executor/#install","title":"Install","text":"<p>Ensure that <code>garf-executors</code> library is installed with OpenSearch support:</p> <pre><code>pip install garf-executors[opensearch]\n</code></pre>"},{"location":"usage/executors/opensearch-executor/#usage","title":"Usage","text":"<p>After <code>garf-executors</code> is installed you can use <code>garf</code> utility to perform fetching.</p> bashPythonserver <p><pre><code>echo \"SELECT campaign_id FROM opensearch_index\" &gt; query.sql\n\ngarf query.sql --source opensearch --output csv\n</code></pre> where</p> <ul> <li><code>query</code>- local or remote path(s) to files with queries.</li> <li><code>output</code> - output supported by <code>garf-io</code> library.</li> </ul> <pre><code>from garf.executors.opensearch_executor import OpenSearchQueryExecutor\nfrom opensearchpy import OpenSearch\n\n\nclient = OpenSearch(\n    hosts = [{'host': 'localhost', 'port': 9200}],\n    http_compress = True, # enables gzip compression for request bodies\n    http_auth = ('admin', 'admin'),\n    use_ssl = True,\n    verify_certs = False,\n    ssl_assert_hostname = False,\n    ssl_show_warn = False\n)\n\nquery_executor = OpenSearchQueryExecutor(client=client)\n\nquery_text = \"SELECT campaign_id FROM opensearch_index\"\n\n# execute query and get report back\nreport = query_executor.execute(query=query_text, title=\"campaign\")\n\n# execute query and save results to `campaign.csv`\nquery_executor.execute(\n  query=query_text,\n  title=\"campaign\",\n  context={'writer': 'csv'}\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"opensearch\",\n  \"query\": \"SELECT campaign_id FROM opensearch_index\",\n  \"title\": \"campaign\",\n  \"context\": {\n    \"writer\": \"csv\"\n  }\n}'\n</code></pre>"},{"location":"usage/executors/opensearch-executor/#parameters","title":"Parameters","text":""},{"location":"usage/executors/opensearch-executor/#hosts","title":"hosts","text":"<p>By default <code>garf</code> expects opensearch running on <code>localhost:9200</code>. You can adjust this via <code>hosts</code> parameter (each host should be provided in <code>host:port</code> format).</p> bashPythonserver <pre><code>echo \"SELECT campaign_id FROM opensearch_index\" &gt; query.sql\n\ngarf query.sql --source opensearch \\\n  --output csv \\\n  --source.hosts=opensearch1:9200,opensearch2:9200\n</code></pre> <pre><code>from garf.executors.opensearch_executor import OpenSearchQueryExecutor\n\nquery_executor = OpenSearchQueryExecutor(\n  hosts=['opensearch1:9200', 'opensearch2:9200']\n)\n\nquery_text = \"SELECT campaign_id FROM opensearch_index\"\n\n# execute query and get report back\nreport = query_executor.execute(query=query_text, title=\"campaign\")\n\n# execute query and save results to `campaign.csv`\nquery_executor.execute(\n  query=query_text,\n  title=\"campaign\",\n  context={'writer': 'csv'}\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"opensearch\",\n  \"query\": \"SELECT campaign_id FROM opensearch_index\",\n  \"title\": \"campaign\",\n  \"context\": {\n    \"writer\": \"csv\",\n    \"fetcher_parameters\": {\n      \"hosts\":  [\n        \"opensearch1:9200\",\n        \"opensearch2:9200\"\n      ]\n    }\n  },\n}'\n</code></pre>"},{"location":"usage/executors/opensearch-executor/#client","title":"client","text":"<p><code>OpenSearchQueryExecutor</code> can be customized with <code>opensearch-py</code> client.</p> Python <pre><code>from garf.executors.opensearch_executor import OpenSearchQueryExecutor\nfrom opensearchpy import OpenSearch\n\n\nclient = OpenSearch(\n  hosts = [{'host': 'localhost', 'port': 9200}],\n  http_compress = True,\n  http_auth = ('admin', 'admin'),\n  use_ssl = True,\n  verify_certs = False,\n  ssl_assert_hostname = False,\n  ssl_show_warn = False\n)\n\nquery_executor = OpenSearchQueryExecutor(client=client)\n</code></pre>"},{"location":"usage/executors/sql-executor/","title":"SQL Executor","text":"<p>SQL executor allows you to execute SQL code via any database supported by SqlAlchemy.</p>"},{"location":"usage/executors/sql-executor/#install","title":"Install","text":"<p>Ensure that <code>garf-executors</code> library is installed with SqlAlchemy support:</p> <pre><code>pip install garf-executors[sql]\n</code></pre>"},{"location":"usage/executors/sql-executor/#usage","title":"Usage","text":"<p>After <code>garf-executors</code> is installed you can use <code>garf</code> utility to perform fetching.</p> <p>Important</p> <p><code>sql</code> executor expects a <code>connection_string</code> parameter in SqlAlchemy format. If it's not provided queries are executed via in-memory sqlite database.</p> bashPythonserver <p><pre><code>echo \"SELECT campaign_id FROM table\" &gt; query.sql\n\ngarf query.sql --source sqldb \\\n  --output csv\n</code></pre> where</p> <ul> <li><code>query</code>- local or remote path(s) to files with queries.</li> <li><code>output</code> - output supported by <code>garf-io</code> library.</li> </ul> <pre><code>from garf.executors.sql_executor import SqlAlchemyQueryExecutor\n\n\nquery_executor = SqlAlchemyQueryExecutor()\n\nquery_text = \"SELECT campaign_id FROM table\"\n\n# execute query and get report back\nreport = query_executor.execute(query=query_text, title=\"campaign\")\n\n# execute query and save results to `campaign.csv`\nquery_executor.execute(\n  query=query_text,\n  title=\"campaign\",\n  context={'writer': 'csv'}\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"sqldb\",\n  \"query\": \"SELECT campaign_id FROM table\",\n  \"title\": \"campaign\",\n  \"context\": {\n    \"writer\": \"csv\"\n  }\n}'\n</code></pre>"},{"location":"usage/executors/sql-executor/#parameters","title":"Parameters","text":""},{"location":"usage/executors/sql-executor/#connection_string","title":"connection_string","text":"<p><code>SqlAlchemyQueryExecutor</code> requires connection string to the database.</p> cliPythonserver <pre><code>garf query.sql --source sqldb \\\n  --output csv \\\n  --sqldb.connection_string=DB_CONNECTION_STRING\n</code></pre> <pre><code>from garf.executors.sql_executor import SqlAlchemyQueryExecutor\n\nquery_executor = (\n  SqlAlchemyQueryExecutor.from_connection_string('DB_CONNECTION_STRING')\n)\n</code></pre> <pre><code>curl -X 'POST' \\\n  'http://127.0.0.1:8000/api/execute' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n  \"source\": \"sqldb\",\n  \"query\": \"SELECT campaign_id FROM table\",\n  \"title\": \"campaign\",\n  \"context\": {\n    \"writer\": \"csv\",\n    \"fetcher_parameters\": {\n      \"connection_string\": \"DB_CONNECTION_STRING\"\n    }\n  }\n}'\n</code></pre>"},{"location":"usage/writers/bq-writer/","title":"BigQuery","text":"<p>Important</p> <p>To save data to BigQuery install <code>garf-io</code> with BigQuery support</p> <pre><code>pip install garf-io[bq]\n</code></pre> <p><code>bq</code> writer allows you to save <code>GarfReport</code> to BigQuery table.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output bq\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import bigquery_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = bigquery_writer.BigQueryWriter()\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/bq-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/bq-writer/#project","title":"Project","text":"<p>By default reports are saved to <code>GOOGLE_CLOUD_PROJECT</code>. You can overwrite it with <code>project</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output bq \\\n  --bq.project=PROJECT_ID\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import bigquery_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = bigquery_writer.BigQueryWriter(project=\"PROJECT_ID\")\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/bq-writer/#dataset","title":"Dataset","text":"<p>By default reports are saved to <code>garf</code> dataset. You can overwrite it with <code>dataset</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output bq \\\n  --bq.dataset=DATASET\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import bigquery_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = bigquery_writer.BigQueryWriter(dataset=\"DATASET\")\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/bq-writer/#location","title":"Location","text":"<p>By default reports are saved to <code>US</code> location. You can overwrite it with <code>location</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output bq \\\n  --bq.location=LOCATION\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import bigquery_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = bigquery_writer.BigQueryWriter(location=\"LOCATION\")\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/bq-writer/#write-disposition","title":"Write disposition","text":"<p>By default reports overwrite any existing data. You can overwrite it with <code>write_disposition</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output bq \\\n  --bq.write_disposition=DISPOSITION\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import bigquery_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = bigquery_writer.BigQueryWriter(write_disposition=\"DISPOSITION\")\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/console-writer/","title":"Console","text":"<p><code>console</code> writer allows you to print <code>GarfReport</code> to standard output in the terminal.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output console\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import console_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = console_writer.ConsoleWriter()\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/console-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/console-writer/#format","title":"Format","text":"<p>For <code>console</code> writer you can specify the output format:</p> <ul> <li><code>table</code> - rich table (default).</li> <li><code>json</code> - JSON.</li> <li><code>jsonl</code> - JSON lines</li> </ul> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output console \\\n  --console.format=json\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import console_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = console_writer.ConsoleWriter(format='json')\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/console-writer/#page-size","title":"Page size","text":"<p>If you're using <code>console</code> writer with <code>table</code> format option, you can specify <code>page_size</code> parameter to print N rows to the console.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output console \\\n  --console.page-size=100\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import console_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = console_writer.ConsoleWriter(page_size=100)\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/csv-writer/","title":"CSV","text":"<p><code>csv</code> writer allows you to save <code>GarfReport</code> as a CSV file to local or remote storage.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output csv\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import csv_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = csv_writer.CsvWriter()\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/csv-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/csv-writer/#destination-folder","title":"Destination folder","text":"<p>For <code>csv</code> writer you can specify the local or remote folder to store results. I.e. if you want to write results to Google Cloud Storage bucket <code>gs://PROJECT_ID/bucket</code>, you need to provide <code>destination_folder</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output csv \\\n  --csv.destination-folder=gs://PROJECT_ID/bucket\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import csv_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = csv_writer.CsvWriter(destination_folder='gs://PROJECT_ID/bucket/')\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/elasticsearch-writer/","title":"ElasticSearch","text":"<p>Important</p> <p>To save data to Elasticsearch install <code>garf-io</code> with Elasticsearch support</p> <pre><code>pip install garf-io[elasticsearch]\n</code></pre> <p><code>elasticsearch</code> writer allows you to index <code>GarfReport</code> to Elasticsearch.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output elasticsearch \\\n  --elasticsearch.hosts=localhost:9200\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import elasticsearch_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = elasticsearch_writer.ElasticsearchWriter(hosts='localhost:9200')\nwriter.write(sample_report, 'index_name')\n</code></pre>"},{"location":"usage/writers/elasticsearch-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/elasticsearch-writer/#hosts","title":"Hosts","text":"<p>By default it connects to <code>localhost:9200</code>. You can overwrite it with <code>hosts</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output elasticsearch \\\n  --elasticsearch.hosts=host1:9200,host2:9200\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import elasticsearch_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = elasticsearch_writer.ElasticsearchWriter(hosts=[\"host1:9200\", \"host2:9200\"])\nwriter.write(sample_report, 'index_name')\n</code></pre>"},{"location":"usage/writers/elasticsearch-writer/#authentication","title":"Authentication","text":"<p>You can provide authentication credentials using <code>http_auth</code> parameter (Python only).</p> python <pre><code>from garf.core import report\nfrom garf.io.writers import elasticsearch_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = elasticsearch_writer.ElasticsearchWriter(\n    hosts='localhost:9200',\n    http_auth=('user', 'password')\n)\nwriter.write(sample_report, 'index_name')\n</code></pre>"},{"location":"usage/writers/excel-writer/","title":"Excel","text":"<p>Important</p> <p>To save data to Excel install <code>garf-io</code> with Excel support</p> <pre><code>pip install garf-io[excel]\n</code></pre> <p><code>excel</code> writer allows you to save <code>GarfReport</code> to Excel files.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output excel\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import excel_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = excel_writer.ExcelWriter()\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/excel-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/excel-writer/#destination-folder","title":"Destination Folder","text":"<p>By default reports are saved to current working directory. You can overwrite it with <code>destination_folder</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output excel \\\n  --excel.destination_folder=/path/to/folder\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import excel_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = excel_writer.ExcelWriter(destination_folder=\"/path/to/folder\")\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/excel-writer/#file","title":"File","text":"<p>You can specify a single file to write multiple reports (sheets) to using the <code>file</code> parameter. When <code>file</code> is specified, the destination argument in <code>write</code> becomes the sheet name.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output excel \\\n  --excel.file=report.xlsx\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import excel_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = excel_writer.ExcelWriter(file=\"report.xlsx\")\nwriter.write(sample_report, 'sheet_name')\n</code></pre>"},{"location":"usage/writers/json-writer/","title":"Json","text":"<p><code>json</code> writer allows you to save <code>GarfReport</code> as JSON or JSONL file to local or remote storage.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output json\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import json_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = json_writer.JsonWriter()\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/json-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/json-writer/#destination-folder","title":"Destination folder","text":"<p>You can specify the local or remote folder to store results. I.e. if you want to write results to Google Cloud Storage bucket <code>gs://PROJECT_ID/bucket</code>, you need to provide <code>destination_folder</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output json \\\n  --json.destination-folder=gs://PROJECT_ID/bucket\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import json_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = json_writer.JsonWriter(destination_folder='gs://PROJECT_ID/bucket/')\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/json-writer/#format","title":"Format","text":"<p>You can specify the output format:</p> <ul> <li><code>json</code> - JSON (default)</li> <li><code>jsonl</code> - JSON lines</li> </ul> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output json \\\n  --json.format=jsonl\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import json_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = json_writer.JsonWriter(format='jsonl')\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/kafka-writer/","title":"Kafka","text":"<p>Important</p> <p>To save data to Kafka install <code>garf-io</code> with Kafka support</p> <pre><code>pip install garf-io[kafka]\n</code></pre> <p><code>kafka</code> writer allows you to publish <code>GarfReport</code> to a Kafka topic.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output kafka \\\n  --kafka.bootstrap_servers=localhost:9092\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import kafka_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = kafka_writer.KafkaWriter(bootstrap_servers='localhost:9092')\nwriter.write(sample_report, 'topic_name')\n</code></pre>"},{"location":"usage/writers/kafka-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/kafka-writer/#bootstrap-servers","title":"Bootstrap Servers","text":"<p>By default it connects to <code>localhost:9092</code>. You can overwrite it with <code>bootstrap_servers</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output kafka \\\n  --kafka.bootstrap_servers=broker1:9092,broker2:9092\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import kafka_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = kafka_writer.KafkaWriter(bootstrap_servers=\"broker1:9092,broker2:9092\")\nwriter.write(sample_report, 'topic_name')\n</code></pre>"},{"location":"usage/writers/opensearch-writer/","title":"OpenSearch","text":"<p>Important</p> <p>To save data to OpenSearch install <code>garf-io</code> with OpenSearch support</p> <pre><code>pip install garf-io[opensearch]\n</code></pre> <p><code>opensearch</code> writer allows you to index <code>GarfReport</code> to OpenSearch.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output opensearch \\\n  --opensearch.hosts=localhost:9200\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import opensearch_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = opensearch_writer.OpenSearchWriter(hosts='localhost:9200')\nwriter.write(sample_report, 'index_name')\n</code></pre>"},{"location":"usage/writers/opensearch-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/opensearch-writer/#hosts","title":"Hosts","text":"<p>By default it connects to <code>localhost:9200</code>. You can overwrite it with <code>hosts</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output opensearch \\\n  --opensearch.hosts=host1:9200,host2:9200\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import opensearch_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = opensearch_writer.OpenSearchWriter(hosts=[\"host1:9200\", \"host2:9200\"])\nwriter.write(sample_report, 'index_name')\n</code></pre>"},{"location":"usage/writers/opensearch-writer/#authentication","title":"Authentication","text":"<p>You can provide authentication credentials using <code>http_auth</code> parameter (Python only).</p> python <pre><code>from garf.core import report\nfrom garf.io.writers import opensearch_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = opensearch_writer.OpenSearchWriter(\n    hosts='localhost:9200',\n    http_auth=('user', 'password')\n)\nwriter.write(sample_report, 'index_name')\n</code></pre>"},{"location":"usage/writers/pubsub-writer/","title":"Google PubSub","text":"<p>Important</p> <p>To save data to Google Cloud Pub/Sub install <code>garf-io</code> with PubSub support</p> <pre><code>pip install garf-io[pubsub]\n</code></pre> <p><code>pubsub</code> writer allows you to publish <code>GarfReport</code> to a Google Cloud Pub/Sub topic.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output pubsub \\\n  --pubsub.project=PROJECT_ID\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import pubsub_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = pubsub_writer.PubSubWriter(project='PROJECT_ID')\nwriter.write(sample_report, 'topic_name')\n</code></pre>"},{"location":"usage/writers/pubsub-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/pubsub-writer/#project","title":"Project","text":"<p>By default it uses <code>GOOGLE_CLOUD_PROJECT</code> environment variable. You can overwrite it with <code>project</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output pubsub \\\n  --pubsub.project=ANOTHER_PROJECT_ID\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import pubsub_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = pubsub_writer.PubSubWriter(project=\"ANOTHER_PROJECT_ID\")\nwriter.write(sample_report, 'topic_name')\n</code></pre>"},{"location":"usage/writers/sheets-writer/","title":"Google Sheets","text":"<p><code>sheets</code> writer allows you to save <code>GarfReport</code> to Google Sheets.</p> <p>Important</p> <p>To save data to Google Sheets install <code>garf-io</code> with Google Sheets support</p> <pre><code>pip install garf-io[sheets]\n</code></pre> <p><code>garf</code> uses gspread to write data to Google Sheets needs to be configured.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output sheets\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import sheets_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = sheets_writer.SheetsWriter()\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/sheets-writer/#parameters","title":"Parameters","text":""},{"location":"usage/writers/sheets-writer/#spreadsheet_url","title":"spreadsheet_url","text":"<p>By default reports are saved to a new spreadsheet. You can overwrite it with <code>spreadsheet_url</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output sheets \\\n  --sheets.spreadsheet_url=SPREADSHEET_URL\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import sheets_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = sheets_writer.SheetsWriter(spreadsheet_url=SPREADSHEET_URL)\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/sheets-writer/#share_with","title":"share_with","text":"<p>If you want to share created or existing spreadsheet, you can specify email(s) via <code>share_with</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output sheets \\\n  --sheets.share_with=your@email.com\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import sheets_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = sheets_writer.SheetsWriter(share_with='your@email.com')\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/sheets-writer/#is_append","title":"is_append","text":"<p>By default new report overwrites old report in worksheets. You can adjust this behaviour with <code>is_append</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output sheets \\\n  --sheets.is_append\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import sheets_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = sheets_writer.SheetsWriter(is_append=True)\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/sheets-writer/#credentials_file","title":"credentials_file","text":"<p><code>garf</code> uses gspread to write data to Google Sheets which expects credentials file in <code>~/.config/gspread</code> folder.</p> <p>You can adjust it via <code>credentials_file</code> parameter.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output sheets \\\n  --sheets.credentials_file=/path/to/credentials.json\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import sheets_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = sheets_writer.SheetsWriter(credentials_file='/path/to/credentials.json')\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/sheets-writer/#auth_mode","title":"auth_mode","text":"<p>By default <code>garf</code> will try to authenticate with user credentials You can overwrite it via <code>auth_mode</code> parameter (which can be either <code>oauth</code> or <code>service_account</code>)</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output sheets \\\n  --sheets.auth_mode=service_account\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import sheets_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = sheets_writer.SheetsWriter(auth_mode='service_account')\nwriter.write(sample_report, 'query')\n</code></pre>"},{"location":"usage/writers/sql-writer/","title":"SQL","text":"<p>Important</p> <p>To save data to Google Sheets install <code>garf-io</code> with SqlAlchemy support</p> <pre><code>pip install garf-io[sqlalchemy]\n</code></pre> <p><code>sqldb</code> writer allows you to save <code>GarfReport</code> to SqlAlchemy supported table databases.</p> clipython <pre><code>garf query.sql --source API_SOURCE \\\n  --output sqldb\n</code></pre> <pre><code>from garf.core import report\nfrom garf.io.writers import sqldb_writer\n\n# Create example report\nsample_report = report.GarfReport(results=[[1]], column_names=['one'])\n\nwriter = sqldb_writer.SqlAlchemyWriter(\n  connection_string=SQLALCHEMY_CONNECTION_STRING\n)\nwriter.write(sample_report, 'query')\n</code></pre>"}]}